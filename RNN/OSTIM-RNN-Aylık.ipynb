{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "becc7727-ca93-4db3-9a8b-9743b0f79d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "C:\\Users\\musab\\AppData\\Local\\Temp\\ipykernel_13504\\2208017571.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  OSTIM_df.drop(\"Date\", axis=1, inplace=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 1, 20)             440       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 20)             0         \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 10)                310       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 10)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 761\n",
      "Trainable params: 761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1985\n",
      "Epoch 1: val_loss improved from inf to 0.21114, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 5s 626ms/step - loss: 0.1985 - val_loss: 0.2111\n",
      "Epoch 2/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0661\n",
      "Epoch 2: val_loss improved from 0.21114 to 0.21038, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.1960 - val_loss: 0.2104\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1966\n",
      "Epoch 3: val_loss improved from 0.21038 to 0.20963, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.1966 - val_loss: 0.2096\n",
      "Epoch 4/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0680\n",
      "Epoch 4: val_loss improved from 0.20963 to 0.20888, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1954 - val_loss: 0.2089\n",
      "Epoch 5/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0672\n",
      "Epoch 5: val_loss improved from 0.20888 to 0.20813, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1964 - val_loss: 0.2081\n",
      "Epoch 6/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0688\n",
      "Epoch 6: val_loss improved from 0.20813 to 0.20739, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1911 - val_loss: 0.2074\n",
      "Epoch 7/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0674\n",
      "Epoch 7: val_loss improved from 0.20739 to 0.20665, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.1962 - val_loss: 0.2066\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1874\n",
      "Epoch 8: val_loss improved from 0.20665 to 0.20591, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1874 - val_loss: 0.2059\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1908\n",
      "Epoch 9: val_loss improved from 0.20591 to 0.20518, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.1908 - val_loss: 0.2052\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1924\n",
      "Epoch 10: val_loss improved from 0.20518 to 0.20445, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.1924 - val_loss: 0.2044\n",
      "Epoch 11/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0644\n",
      "Epoch 11: val_loss improved from 0.20445 to 0.20372, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1957 - val_loss: 0.2037\n",
      "Epoch 12/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0626\n",
      "Epoch 12: val_loss improved from 0.20372 to 0.20299, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1935 - val_loss: 0.2030\n",
      "Epoch 13/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0627\n",
      "Epoch 13: val_loss improved from 0.20299 to 0.20227, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1810 - val_loss: 0.2023\n",
      "Epoch 14/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0616\n",
      "Epoch 14: val_loss improved from 0.20227 to 0.20155, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1829 - val_loss: 0.2015\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1861\n",
      "Epoch 15: val_loss improved from 0.20155 to 0.20083, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1861 - val_loss: 0.2008\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1822\n",
      "Epoch 16: val_loss improved from 0.20083 to 0.20012, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1822 - val_loss: 0.2001\n",
      "Epoch 17/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0624\n",
      "Epoch 17: val_loss improved from 0.20012 to 0.19940, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1853 - val_loss: 0.1994\n",
      "Epoch 18/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0608\n",
      "Epoch 18: val_loss improved from 0.19940 to 0.19869, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.1884 - val_loss: 0.1987\n",
      "Epoch 19/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0625\n",
      "Epoch 19: val_loss improved from 0.19869 to 0.19797, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1848 - val_loss: 0.1980\n",
      "Epoch 20/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0627\n",
      "Epoch 20: val_loss improved from 0.19797 to 0.19726, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.1812 - val_loss: 0.1973\n",
      "Epoch 21/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0607\n",
      "Epoch 21: val_loss improved from 0.19726 to 0.19654, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1832 - val_loss: 0.1965\n",
      "Epoch 22/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0622\n",
      "Epoch 22: val_loss improved from 0.19654 to 0.19583, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1830 - val_loss: 0.1958\n",
      "Epoch 23/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0624\n",
      "Epoch 23: val_loss improved from 0.19583 to 0.19512, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1834 - val_loss: 0.1951\n",
      "Epoch 24/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0575\n",
      "Epoch 24: val_loss improved from 0.19512 to 0.19442, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1834 - val_loss: 0.1944\n",
      "Epoch 25/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0595\n",
      "Epoch 25: val_loss improved from 0.19442 to 0.19373, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1846 - val_loss: 0.1937\n",
      "Epoch 26/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0604\n",
      "Epoch 26: val_loss improved from 0.19373 to 0.19304, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.1780 - val_loss: 0.1930\n",
      "Epoch 27/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0597\n",
      "Epoch 27: val_loss improved from 0.19304 to 0.19234, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1831 - val_loss: 0.1923\n",
      "Epoch 28/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0580\n",
      "Epoch 28: val_loss improved from 0.19234 to 0.19165, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.1775 - val_loss: 0.1917\n",
      "Epoch 29/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0583\n",
      "Epoch 29: val_loss improved from 0.19165 to 0.19095, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1770 - val_loss: 0.1910\n",
      "Epoch 30/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0584\n",
      "Epoch 30: val_loss improved from 0.19095 to 0.19026, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1727 - val_loss: 0.1903\n",
      "Epoch 31/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0587\n",
      "Epoch 31: val_loss improved from 0.19026 to 0.18957, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.1860 - val_loss: 0.1896\n",
      "Epoch 32/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0539\n",
      "Epoch 32: val_loss improved from 0.18957 to 0.18889, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1755 - val_loss: 0.1889\n",
      "Epoch 33/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0561\n",
      "Epoch 33: val_loss improved from 0.18889 to 0.18820, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.1729 - val_loss: 0.1882\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1703\n",
      "Epoch 34: val_loss improved from 0.18820 to 0.18752, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.1703 - val_loss: 0.1875\n",
      "Epoch 35/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0369\n",
      "Epoch 35: val_loss improved from 0.18752 to 0.18685, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.1774 - val_loss: 0.1868\n",
      "Epoch 36/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0569\n",
      "Epoch 36: val_loss improved from 0.18685 to 0.18617, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1688 - val_loss: 0.1862\n",
      "Epoch 37/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0555\n",
      "Epoch 37: val_loss improved from 0.18617 to 0.18550, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.1711 - val_loss: 0.1855\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1672\n",
      "Epoch 38: val_loss improved from 0.18550 to 0.18483, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1672 - val_loss: 0.1848\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1666\n",
      "Epoch 39: val_loss improved from 0.18483 to 0.18416, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1666 - val_loss: 0.1842\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1722\n",
      "Epoch 40: val_loss improved from 0.18416 to 0.18349, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1722 - val_loss: 0.1835\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1733\n",
      "Epoch 41: val_loss improved from 0.18349 to 0.18281, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1733 - val_loss: 0.1828\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1655\n",
      "Epoch 42: val_loss improved from 0.18281 to 0.18214, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1655 - val_loss: 0.1821\n",
      "Epoch 43/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0517\n",
      "Epoch 43: val_loss improved from 0.18214 to 0.18147, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1665 - val_loss: 0.1815\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1683\n",
      "Epoch 44: val_loss improved from 0.18147 to 0.18080, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1683 - val_loss: 0.1808\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1703\n",
      "Epoch 45: val_loss improved from 0.18080 to 0.18014, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1703 - val_loss: 0.1801\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1662\n",
      "Epoch 46: val_loss improved from 0.18014 to 0.17947, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1662 - val_loss: 0.1795\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1714\n",
      "Epoch 47: val_loss improved from 0.17947 to 0.17882, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1714 - val_loss: 0.1788\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1644\n",
      "Epoch 48: val_loss improved from 0.17882 to 0.17816, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.1644 - val_loss: 0.1782\n",
      "Epoch 49/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0511\n",
      "Epoch 49: val_loss improved from 0.17816 to 0.17750, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1657 - val_loss: 0.1775\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1654\n",
      "Epoch 50: val_loss improved from 0.17750 to 0.17684, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1654 - val_loss: 0.1768\n",
      "Epoch 51/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0468\n",
      "Epoch 51: val_loss improved from 0.17684 to 0.17618, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1628 - val_loss: 0.1762\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1666\n",
      "Epoch 52: val_loss improved from 0.17618 to 0.17551, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1666 - val_loss: 0.1755\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1613\n",
      "Epoch 53: val_loss improved from 0.17551 to 0.17485, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1613 - val_loss: 0.1749\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1591\n",
      "Epoch 54: val_loss improved from 0.17485 to 0.17420, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1591 - val_loss: 0.1742\n",
      "Epoch 55/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0475\n",
      "Epoch 55: val_loss improved from 0.17420 to 0.17355, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1518 - val_loss: 0.1736\n",
      "Epoch 56/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0462\n",
      "Epoch 56: val_loss improved from 0.17355 to 0.17292, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.1581 - val_loss: 0.1729\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1560\n",
      "Epoch 57: val_loss improved from 0.17292 to 0.17229, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1560 - val_loss: 0.1723\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1569\n",
      "Epoch 58: val_loss improved from 0.17229 to 0.17166, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.1569 - val_loss: 0.1717\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1539\n",
      "Epoch 59: val_loss improved from 0.17166 to 0.17103, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.1539 - val_loss: 0.1710\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1587\n",
      "Epoch 60: val_loss improved from 0.17103 to 0.17041, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1587 - val_loss: 0.1704\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1555\n",
      "Epoch 61: val_loss improved from 0.17041 to 0.16979, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.1555 - val_loss: 0.1698\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1531\n",
      "Epoch 62: val_loss improved from 0.16979 to 0.16916, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.1531 - val_loss: 0.1692\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1562\n",
      "Epoch 63: val_loss improved from 0.16916 to 0.16853, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1562 - val_loss: 0.1685\n",
      "Epoch 64/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0300\n",
      "Epoch 64: val_loss improved from 0.16853 to 0.16791, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.1516 - val_loss: 0.1679\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1541\n",
      "Epoch 65: val_loss improved from 0.16791 to 0.16730, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1541 - val_loss: 0.1673\n",
      "Epoch 66/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0445\n",
      "Epoch 66: val_loss improved from 0.16730 to 0.16669, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1557 - val_loss: 0.1667\n",
      "Epoch 67/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0283\n",
      "Epoch 67: val_loss improved from 0.16669 to 0.16608, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.1481 - val_loss: 0.1661\n",
      "Epoch 68/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0441\n",
      "Epoch 68: val_loss improved from 0.16608 to 0.16546, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1548 - val_loss: 0.1655\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1508\n",
      "Epoch 69: val_loss improved from 0.16546 to 0.16484, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1508 - val_loss: 0.1648\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1520\n",
      "Epoch 70: val_loss improved from 0.16484 to 0.16423, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1520 - val_loss: 0.1642\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1522\n",
      "Epoch 71: val_loss improved from 0.16423 to 0.16362, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1522 - val_loss: 0.1636\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1462\n",
      "Epoch 72: val_loss improved from 0.16362 to 0.16301, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1462 - val_loss: 0.1630\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1503\n",
      "Epoch 73: val_loss improved from 0.16301 to 0.16240, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 0.1503 - val_loss: 0.1624\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1529\n",
      "Epoch 74: val_loss improved from 0.16240 to 0.16180, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1529 - val_loss: 0.1618\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1427\n",
      "Epoch 75: val_loss improved from 0.16180 to 0.16120, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.1427 - val_loss: 0.1612\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1445\n",
      "Epoch 76: val_loss improved from 0.16120 to 0.16060, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1445 - val_loss: 0.1606\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1520\n",
      "Epoch 77: val_loss improved from 0.16060 to 0.15999, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1520 - val_loss: 0.1600\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1489\n",
      "Epoch 78: val_loss improved from 0.15999 to 0.15939, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1489 - val_loss: 0.1594\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1445\n",
      "Epoch 79: val_loss improved from 0.15939 to 0.15879, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.1445 - val_loss: 0.1588\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1471\n",
      "Epoch 80: val_loss improved from 0.15879 to 0.15819, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.1471 - val_loss: 0.1582\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1434\n",
      "Epoch 81: val_loss improved from 0.15819 to 0.15759, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1434 - val_loss: 0.1576\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1456\n",
      "Epoch 82: val_loss improved from 0.15759 to 0.15699, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 0.1456 - val_loss: 0.1570\n",
      "Epoch 83/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0249\n",
      "Epoch 83: val_loss improved from 0.15699 to 0.15639, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.1402 - val_loss: 0.1564\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1396\n",
      "Epoch 84: val_loss improved from 0.15639 to 0.15579, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1396 - val_loss: 0.1558\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1365\n",
      "Epoch 85: val_loss improved from 0.15579 to 0.15519, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1365 - val_loss: 0.1552\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1411\n",
      "Epoch 86: val_loss improved from 0.15519 to 0.15459, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1411 - val_loss: 0.1546\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1464\n",
      "Epoch 87: val_loss improved from 0.15459 to 0.15400, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1464 - val_loss: 0.1540\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1406\n",
      "Epoch 88: val_loss improved from 0.15400 to 0.15341, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.1406 - val_loss: 0.1534\n",
      "Epoch 89/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0388\n",
      "Epoch 89: val_loss improved from 0.15341 to 0.15283, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1428 - val_loss: 0.1528\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1334\n",
      "Epoch 90: val_loss improved from 0.15283 to 0.15224, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1334 - val_loss: 0.1522\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1390\n",
      "Epoch 91: val_loss improved from 0.15224 to 0.15166, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1390 - val_loss: 0.1517\n",
      "Epoch 92/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0398\n",
      "Epoch 92: val_loss improved from 0.15166 to 0.15108, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1355 - val_loss: 0.1511\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1353\n",
      "Epoch 93: val_loss improved from 0.15108 to 0.15050, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1353 - val_loss: 0.1505\n",
      "Epoch 94/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0340\n",
      "Epoch 94: val_loss improved from 0.15050 to 0.14991, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1402 - val_loss: 0.1499\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1405\n",
      "Epoch 95: val_loss improved from 0.14991 to 0.14933, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1405 - val_loss: 0.1493\n",
      "Epoch 96/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0369\n",
      "Epoch 96: val_loss improved from 0.14933 to 0.14875, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1367 - val_loss: 0.1487\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1355\n",
      "Epoch 97: val_loss improved from 0.14875 to 0.14817, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1355 - val_loss: 0.1482\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1372\n",
      "Epoch 98: val_loss improved from 0.14817 to 0.14759, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1372 - val_loss: 0.1476\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1384\n",
      "Epoch 99: val_loss improved from 0.14759 to 0.14701, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1384 - val_loss: 0.1470\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1343\n",
      "Epoch 100: val_loss improved from 0.14701 to 0.14644, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.1343 - val_loss: 0.1464\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1305\n",
      "Epoch 101: val_loss improved from 0.14644 to 0.14588, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1305 - val_loss: 0.1459\n",
      "Epoch 102/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0343\n",
      "Epoch 102: val_loss improved from 0.14588 to 0.14532, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.1378 - val_loss: 0.1453\n",
      "Epoch 103/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0339\n",
      "Epoch 103: val_loss improved from 0.14532 to 0.14475, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1290 - val_loss: 0.1448\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1323\n",
      "Epoch 104: val_loss improved from 0.14475 to 0.14419, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.1323 - val_loss: 0.1442\n",
      "Epoch 105/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0313\n",
      "Epoch 105: val_loss improved from 0.14419 to 0.14364, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1330 - val_loss: 0.1436\n",
      "Epoch 106/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0330\n",
      "Epoch 106: val_loss improved from 0.14364 to 0.14308, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1359 - val_loss: 0.1431\n",
      "Epoch 107/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0331\n",
      "Epoch 107: val_loss improved from 0.14308 to 0.14252, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.1268 - val_loss: 0.1425\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1256\n",
      "Epoch 108: val_loss improved from 0.14252 to 0.14197, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1256 - val_loss: 0.1420\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1274\n",
      "Epoch 109: val_loss improved from 0.14197 to 0.14141, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.1274 - val_loss: 0.1414\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1313\n",
      "Epoch 110: val_loss improved from 0.14141 to 0.14086, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1313 - val_loss: 0.1409\n",
      "Epoch 111/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0334\n",
      "Epoch 111: val_loss improved from 0.14086 to 0.14030, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1301 - val_loss: 0.1403\n",
      "Epoch 112/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0306\n",
      "Epoch 112: val_loss improved from 0.14030 to 0.13975, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1280 - val_loss: 0.1398\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1283\n",
      "Epoch 113: val_loss improved from 0.13975 to 0.13920, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1283 - val_loss: 0.1392\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1192\n",
      "Epoch 114: val_loss improved from 0.13920 to 0.13866, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1192 - val_loss: 0.1387\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1292\n",
      "Epoch 115: val_loss improved from 0.13866 to 0.13811, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1292 - val_loss: 0.1381\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1208\n",
      "Epoch 116: val_loss improved from 0.13811 to 0.13757, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1208 - val_loss: 0.1376\n",
      "Epoch 117/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0292\n",
      "Epoch 117: val_loss improved from 0.13757 to 0.13703, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1236 - val_loss: 0.1370\n",
      "Epoch 118/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0282\n",
      "Epoch 118: val_loss improved from 0.13703 to 0.13649, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.1139 - val_loss: 0.1365\n",
      "Epoch 119/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0312\n",
      "Epoch 119: val_loss improved from 0.13649 to 0.13596, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1255 - val_loss: 0.1360\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1211\n",
      "Epoch 120: val_loss improved from 0.13596 to 0.13543, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1211 - val_loss: 0.1354\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1192\n",
      "Epoch 121: val_loss improved from 0.13543 to 0.13489, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1192 - val_loss: 0.1349\n",
      "Epoch 122/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0288\n",
      "Epoch 122: val_loss improved from 0.13489 to 0.13436, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1257 - val_loss: 0.1344\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1197\n",
      "Epoch 123: val_loss improved from 0.13436 to 0.13383, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1197 - val_loss: 0.1338\n",
      "Epoch 124/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0274\n",
      "Epoch 124: val_loss improved from 0.13383 to 0.13329, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1264 - val_loss: 0.1333\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1205\n",
      "Epoch 125: val_loss improved from 0.13329 to 0.13276, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1205 - val_loss: 0.1328\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1169\n",
      "Epoch 126: val_loss improved from 0.13276 to 0.13224, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1169 - val_loss: 0.1322\n",
      "Epoch 127/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0285\n",
      "Epoch 127: val_loss improved from 0.13224 to 0.13171, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1221 - val_loss: 0.1317\n",
      "Epoch 128/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0278\n",
      "Epoch 128: val_loss improved from 0.13171 to 0.13119, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.1206 - val_loss: 0.1312\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1142\n",
      "Epoch 129: val_loss improved from 0.13119 to 0.13068, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1142 - val_loss: 0.1307\n",
      "Epoch 130/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1210\n",
      "Epoch 130: val_loss improved from 0.13068 to 0.13016, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1210 - val_loss: 0.1302\n",
      "Epoch 131/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0251\n",
      "Epoch 131: val_loss improved from 0.13016 to 0.12965, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1188 - val_loss: 0.1296\n",
      "Epoch 132/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1167\n",
      "Epoch 132: val_loss improved from 0.12965 to 0.12913, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1167 - val_loss: 0.1291\n",
      "Epoch 133/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1176\n",
      "Epoch 133: val_loss improved from 0.12913 to 0.12862, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1176 - val_loss: 0.1286\n",
      "Epoch 134/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1130\n",
      "Epoch 134: val_loss improved from 0.12862 to 0.12810, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.1130 - val_loss: 0.1281\n",
      "Epoch 135/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1209\n",
      "Epoch 135: val_loss improved from 0.12810 to 0.12758, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1209 - val_loss: 0.1276\n",
      "Epoch 136/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1148\n",
      "Epoch 136: val_loss improved from 0.12758 to 0.12706, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1148 - val_loss: 0.1271\n",
      "Epoch 137/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1133\n",
      "Epoch 137: val_loss improved from 0.12706 to 0.12655, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.1133 - val_loss: 0.1265\n",
      "Epoch 138/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0157\n",
      "Epoch 138: val_loss improved from 0.12655 to 0.12603, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.1129 - val_loss: 0.1260\n",
      "Epoch 139/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1115\n",
      "Epoch 139: val_loss improved from 0.12603 to 0.12551, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1115 - val_loss: 0.1255\n",
      "Epoch 140/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0243\n",
      "Epoch 140: val_loss improved from 0.12551 to 0.12500, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.1110 - val_loss: 0.1250\n",
      "Epoch 141/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1056\n",
      "Epoch 141: val_loss improved from 0.12500 to 0.12449, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1056 - val_loss: 0.1245\n",
      "Epoch 142/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0236\n",
      "Epoch 142: val_loss improved from 0.12449 to 0.12399, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1107 - val_loss: 0.1240\n",
      "Epoch 143/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1102\n",
      "Epoch 143: val_loss improved from 0.12399 to 0.12350, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1102 - val_loss: 0.1235\n",
      "Epoch 144/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0228\n",
      "Epoch 144: val_loss improved from 0.12350 to 0.12300, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.1060 - val_loss: 0.1230\n",
      "Epoch 145/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1207\n",
      "Epoch 145: val_loss improved from 0.12300 to 0.12251, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1207 - val_loss: 0.1225\n",
      "Epoch 146/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1055\n",
      "Epoch 146: val_loss improved from 0.12251 to 0.12202, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.1055 - val_loss: 0.1220\n",
      "Epoch 147/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0234\n",
      "Epoch 147: val_loss improved from 0.12202 to 0.12154, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.1083 - val_loss: 0.1215\n",
      "Epoch 148/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0243\n",
      "Epoch 148: val_loss improved from 0.12154 to 0.12105, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.1095 - val_loss: 0.1210\n",
      "Epoch 149/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1077\n",
      "Epoch 149: val_loss improved from 0.12105 to 0.12056, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.1077 - val_loss: 0.1206\n",
      "Epoch 150/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1089\n",
      "Epoch 150: val_loss improved from 0.12056 to 0.12007, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1089 - val_loss: 0.1201\n",
      "Epoch 151/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1021\n",
      "Epoch 151: val_loss improved from 0.12007 to 0.11959, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.1021 - val_loss: 0.1196\n",
      "Epoch 152/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1106\n",
      "Epoch 152: val_loss improved from 0.11959 to 0.11910, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.1106 - val_loss: 0.1191\n",
      "Epoch 153/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1077\n",
      "Epoch 153: val_loss improved from 0.11910 to 0.11861, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1077 - val_loss: 0.1186\n",
      "Epoch 154/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1097\n",
      "Epoch 154: val_loss improved from 0.11861 to 0.11812, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.1097 - val_loss: 0.1181\n",
      "Epoch 155/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1006\n",
      "Epoch 155: val_loss improved from 0.11812 to 0.11764, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.1006 - val_loss: 0.1176\n",
      "Epoch 156/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1013\n",
      "Epoch 156: val_loss improved from 0.11764 to 0.11717, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1013 - val_loss: 0.1172\n",
      "Epoch 157/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1083\n",
      "Epoch 157: val_loss improved from 0.11717 to 0.11669, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1083 - val_loss: 0.1167\n",
      "Epoch 158/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1039\n",
      "Epoch 158: val_loss improved from 0.11669 to 0.11621, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 0.1039 - val_loss: 0.1162\n",
      "Epoch 159/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1034\n",
      "Epoch 159: val_loss improved from 0.11621 to 0.11574, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1034 - val_loss: 0.1157\n",
      "Epoch 160/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0204\n",
      "Epoch 160: val_loss improved from 0.11574 to 0.11526, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.1000 - val_loss: 0.1153\n",
      "Epoch 161/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1072\n",
      "Epoch 161: val_loss improved from 0.11526 to 0.11478, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1072 - val_loss: 0.1148\n",
      "Epoch 162/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1021\n",
      "Epoch 162: val_loss improved from 0.11478 to 0.11431, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.1021 - val_loss: 0.1143\n",
      "Epoch 163/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1047\n",
      "Epoch 163: val_loss improved from 0.11431 to 0.11384, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.1047 - val_loss: 0.1138\n",
      "Epoch 164/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1033\n",
      "Epoch 164: val_loss improved from 0.11384 to 0.11337, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.1033 - val_loss: 0.1134\n",
      "Epoch 165/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1052\n",
      "Epoch 165: val_loss improved from 0.11337 to 0.11291, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1052 - val_loss: 0.1129\n",
      "Epoch 166/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0189\n",
      "Epoch 166: val_loss improved from 0.11291 to 0.11245, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1036 - val_loss: 0.1124\n",
      "Epoch 167/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0215\n",
      "Epoch 167: val_loss improved from 0.11245 to 0.11199, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.1062 - val_loss: 0.1120\n",
      "Epoch 168/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0201\n",
      "Epoch 168: val_loss improved from 0.11199 to 0.11153, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.1012 - val_loss: 0.1115\n",
      "Epoch 169/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0174\n",
      "Epoch 169: val_loss improved from 0.11153 to 0.11108, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0992 - val_loss: 0.1111\n",
      "Epoch 170/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1075\n",
      "Epoch 170: val_loss improved from 0.11108 to 0.11064, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1075 - val_loss: 0.1106\n",
      "Epoch 171/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1005\n",
      "Epoch 171: val_loss improved from 0.11064 to 0.11019, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1005 - val_loss: 0.1102\n",
      "Epoch 172/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0196\n",
      "Epoch 172: val_loss improved from 0.11019 to 0.10974, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.1004 - val_loss: 0.1097\n",
      "Epoch 173/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1022\n",
      "Epoch 173: val_loss improved from 0.10974 to 0.10930, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.1022 - val_loss: 0.1093\n",
      "Epoch 174/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1016\n",
      "Epoch 174: val_loss improved from 0.10930 to 0.10887, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1016 - val_loss: 0.1089\n",
      "Epoch 175/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0968\n",
      "Epoch 175: val_loss improved from 0.10887 to 0.10842, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0968 - val_loss: 0.1084\n",
      "Epoch 176/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0939\n",
      "Epoch 176: val_loss improved from 0.10842 to 0.10798, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0939 - val_loss: 0.1080\n",
      "Epoch 177/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0180\n",
      "Epoch 177: val_loss improved from 0.10798 to 0.10754, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.1017 - val_loss: 0.1075\n",
      "Epoch 178/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0951\n",
      "Epoch 178: val_loss improved from 0.10754 to 0.10709, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0951 - val_loss: 0.1071\n",
      "Epoch 179/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0934\n",
      "Epoch 179: val_loss improved from 0.10709 to 0.10665, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0934 - val_loss: 0.1067\n",
      "Epoch 180/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1046\n",
      "Epoch 180: val_loss improved from 0.10665 to 0.10621, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.1046 - val_loss: 0.1062\n",
      "Epoch 181/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0158\n",
      "Epoch 181: val_loss improved from 0.10621 to 0.10578, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0973 - val_loss: 0.1058\n",
      "Epoch 182/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0882\n",
      "Epoch 182: val_loss improved from 0.10578 to 0.10536, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0882 - val_loss: 0.1054\n",
      "Epoch 183/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0925\n",
      "Epoch 183: val_loss improved from 0.10536 to 0.10493, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0925 - val_loss: 0.1049\n",
      "Epoch 184/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0150\n",
      "Epoch 184: val_loss improved from 0.10493 to 0.10451, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0891 - val_loss: 0.1045\n",
      "Epoch 185/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0160\n",
      "Epoch 185: val_loss improved from 0.10451 to 0.10408, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0849 - val_loss: 0.1041\n",
      "Epoch 186/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0891\n",
      "Epoch 186: val_loss improved from 0.10408 to 0.10366, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0891 - val_loss: 0.1037\n",
      "Epoch 187/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0151\n",
      "Epoch 187: val_loss improved from 0.10366 to 0.10323, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0914 - val_loss: 0.1032\n",
      "Epoch 188/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0906\n",
      "Epoch 188: val_loss improved from 0.10323 to 0.10281, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0906 - val_loss: 0.1028\n",
      "Epoch 189/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 189: val_loss improved from 0.10281 to 0.10239, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0913 - val_loss: 0.1024\n",
      "Epoch 190/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0861\n",
      "Epoch 190: val_loss improved from 0.10239 to 0.10196, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0861 - val_loss: 0.1020\n",
      "Epoch 191/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0952\n",
      "Epoch 191: val_loss improved from 0.10196 to 0.10154, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0952 - val_loss: 0.1015\n",
      "Epoch 192/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0870\n",
      "Epoch 192: val_loss improved from 0.10154 to 0.10113, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0870 - val_loss: 0.1011\n",
      "Epoch 193/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0134\n",
      "Epoch 193: val_loss improved from 0.10113 to 0.10071, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0912 - val_loss: 0.1007\n",
      "Epoch 194/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0927\n",
      "Epoch 194: val_loss improved from 0.10071 to 0.10030, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0927 - val_loss: 0.1003\n",
      "Epoch 195/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0152\n",
      "Epoch 195: val_loss improved from 0.10030 to 0.09990, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0911 - val_loss: 0.0999\n",
      "Epoch 196/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0142\n",
      "Epoch 196: val_loss improved from 0.09990 to 0.09950, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0970 - val_loss: 0.0995\n",
      "Epoch 197/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0912\n",
      "Epoch 197: val_loss improved from 0.09950 to 0.09910, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0912 - val_loss: 0.0991\n",
      "Epoch 198/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0835\n",
      "Epoch 198: val_loss improved from 0.09910 to 0.09870, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0835 - val_loss: 0.0987\n",
      "Epoch 199/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0844\n",
      "Epoch 199: val_loss improved from 0.09870 to 0.09830, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0844 - val_loss: 0.0983\n",
      "Epoch 200/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0122\n",
      "Epoch 200: val_loss improved from 0.09830 to 0.09790, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0903 - val_loss: 0.0979\n",
      "Epoch 201/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0137\n",
      "Epoch 201: val_loss improved from 0.09790 to 0.09751, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0889 - val_loss: 0.0975\n",
      "Epoch 202/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0119\n",
      "Epoch 202: val_loss improved from 0.09751 to 0.09711, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0883 - val_loss: 0.0971\n",
      "Epoch 203/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0879\n",
      "Epoch 203: val_loss improved from 0.09711 to 0.09671, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0879 - val_loss: 0.0967\n",
      "Epoch 204/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0163\n",
      "Epoch 204: val_loss improved from 0.09671 to 0.09632, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0836 - val_loss: 0.0963\n",
      "Epoch 205/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0164\n",
      "Epoch 205: val_loss improved from 0.09632 to 0.09592, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0846 - val_loss: 0.0959\n",
      "Epoch 206/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0141\n",
      "Epoch 206: val_loss improved from 0.09592 to 0.09553, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0831 - val_loss: 0.0955\n",
      "Epoch 207/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0837\n",
      "Epoch 207: val_loss improved from 0.09553 to 0.09514, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0837 - val_loss: 0.0951\n",
      "Epoch 208/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0125\n",
      "Epoch 208: val_loss improved from 0.09514 to 0.09475, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0869 - val_loss: 0.0948\n",
      "Epoch 209/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0176\n",
      "Epoch 209: val_loss improved from 0.09475 to 0.09437, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0847 - val_loss: 0.0944\n",
      "Epoch 210/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0113\n",
      "Epoch 210: val_loss improved from 0.09437 to 0.09398, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0785 - val_loss: 0.0940\n",
      "Epoch 211/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0840\n",
      "Epoch 211: val_loss improved from 0.09398 to 0.09360, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0840 - val_loss: 0.0936\n",
      "Epoch 212/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 212: val_loss improved from 0.09360 to 0.09322, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0848 - val_loss: 0.0932\n",
      "Epoch 213/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0886\n",
      "Epoch 213: val_loss improved from 0.09322 to 0.09284, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0886 - val_loss: 0.0928\n",
      "Epoch 214/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0875\n",
      "Epoch 214: val_loss improved from 0.09284 to 0.09246, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0875 - val_loss: 0.0925\n",
      "Epoch 215/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0781\n",
      "Epoch 215: val_loss improved from 0.09246 to 0.09209, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0781 - val_loss: 0.0921\n",
      "Epoch 216/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0803\n",
      "Epoch 216: val_loss improved from 0.09209 to 0.09172, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0803 - val_loss: 0.0917\n",
      "Epoch 217/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0144\n",
      "Epoch 217: val_loss improved from 0.09172 to 0.09135, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0811 - val_loss: 0.0913\n",
      "Epoch 218/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0820\n",
      "Epoch 218: val_loss improved from 0.09135 to 0.09097, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0820 - val_loss: 0.0910\n",
      "Epoch 219/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0789\n",
      "Epoch 219: val_loss improved from 0.09097 to 0.09060, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0789 - val_loss: 0.0906\n",
      "Epoch 220/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0824\n",
      "Epoch 220: val_loss improved from 0.09060 to 0.09023, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0824 - val_loss: 0.0902\n",
      "Epoch 221/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0134\n",
      "Epoch 221: val_loss improved from 0.09023 to 0.08985, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0801 - val_loss: 0.0899\n",
      "Epoch 222/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0805\n",
      "Epoch 222: val_loss improved from 0.08985 to 0.08948, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0805 - val_loss: 0.0895\n",
      "Epoch 223/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 223: val_loss improved from 0.08948 to 0.08912, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0800 - val_loss: 0.0891\n",
      "Epoch 224/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0793\n",
      "Epoch 224: val_loss improved from 0.08912 to 0.08876, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0793 - val_loss: 0.0888\n",
      "Epoch 225/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0894\n",
      "Epoch 225: val_loss improved from 0.08876 to 0.08840, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0894 - val_loss: 0.0884\n",
      "Epoch 226/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0771\n",
      "Epoch 226: val_loss improved from 0.08840 to 0.08804, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0771 - val_loss: 0.0880\n",
      "Epoch 227/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0734\n",
      "Epoch 227: val_loss improved from 0.08804 to 0.08769, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0734 - val_loss: 0.0877\n",
      "Epoch 228/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0744\n",
      "Epoch 228: val_loss improved from 0.08769 to 0.08734, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0744 - val_loss: 0.0873\n",
      "Epoch 229/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0820\n",
      "Epoch 229: val_loss improved from 0.08734 to 0.08699, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0820 - val_loss: 0.0870\n",
      "Epoch 230/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0725\n",
      "Epoch 230: val_loss improved from 0.08699 to 0.08664, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0725 - val_loss: 0.0866\n",
      "Epoch 231/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0880\n",
      "Epoch 231: val_loss improved from 0.08664 to 0.08629, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0880 - val_loss: 0.0863\n",
      "Epoch 232/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0721\n",
      "Epoch 232: val_loss improved from 0.08629 to 0.08594, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0721 - val_loss: 0.0859\n",
      "Epoch 233/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0794\n",
      "Epoch 233: val_loss improved from 0.08594 to 0.08560, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0794 - val_loss: 0.0856\n",
      "Epoch 234/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0083\n",
      "Epoch 234: val_loss improved from 0.08560 to 0.08525, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0783 - val_loss: 0.0853\n",
      "Epoch 235/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0774\n",
      "Epoch 235: val_loss improved from 0.08525 to 0.08491, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0774 - val_loss: 0.0849\n",
      "Epoch 236/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0069\n",
      "Epoch 236: val_loss improved from 0.08491 to 0.08457, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0763 - val_loss: 0.0846\n",
      "Epoch 237/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0721\n",
      "Epoch 237: val_loss improved from 0.08457 to 0.08424, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0721 - val_loss: 0.0842\n",
      "Epoch 238/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0782\n",
      "Epoch 238: val_loss improved from 0.08424 to 0.08390, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0782 - val_loss: 0.0839\n",
      "Epoch 239/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0751\n",
      "Epoch 239: val_loss improved from 0.08390 to 0.08357, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0751 - val_loss: 0.0836\n",
      "Epoch 240/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0728\n",
      "Epoch 240: val_loss improved from 0.08357 to 0.08325, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0728 - val_loss: 0.0832\n",
      "Epoch 241/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0099\n",
      "Epoch 241: val_loss improved from 0.08325 to 0.08292, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0768 - val_loss: 0.0829\n",
      "Epoch 242/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 242: val_loss improved from 0.08292 to 0.08259, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0675 - val_loss: 0.0826\n",
      "Epoch 243/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0097\n",
      "Epoch 243: val_loss improved from 0.08259 to 0.08227, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0699 - val_loss: 0.0823\n",
      "Epoch 244/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0102\n",
      "Epoch 244: val_loss improved from 0.08227 to 0.08195, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0734 - val_loss: 0.0819\n",
      "Epoch 245/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0757\n",
      "Epoch 245: val_loss improved from 0.08195 to 0.08162, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0757 - val_loss: 0.0816\n",
      "Epoch 246/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0122\n",
      "Epoch 246: val_loss improved from 0.08162 to 0.08130, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0749 - val_loss: 0.0813\n",
      "Epoch 247/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0118\n",
      "Epoch 247: val_loss improved from 0.08130 to 0.08097, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0742 - val_loss: 0.0810\n",
      "Epoch 248/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0092\n",
      "Epoch 248: val_loss improved from 0.08097 to 0.08065, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0695 - val_loss: 0.0807\n",
      "Epoch 249/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0090\n",
      "Epoch 249: val_loss improved from 0.08065 to 0.08033, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0709 - val_loss: 0.0803\n",
      "Epoch 250/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0762\n",
      "Epoch 250: val_loss improved from 0.08033 to 0.08002, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0762 - val_loss: 0.0800\n",
      "Epoch 251/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0717\n",
      "Epoch 251: val_loss improved from 0.08002 to 0.07970, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0717 - val_loss: 0.0797\n",
      "Epoch 252/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0100\n",
      "Epoch 252: val_loss improved from 0.07970 to 0.07939, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0773 - val_loss: 0.0794\n",
      "Epoch 253/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0718\n",
      "Epoch 253: val_loss improved from 0.07939 to 0.07909, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0718 - val_loss: 0.0791\n",
      "Epoch 254/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0076\n",
      "Epoch 254: val_loss improved from 0.07909 to 0.07879, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0783 - val_loss: 0.0788\n",
      "Epoch 255/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0693\n",
      "Epoch 255: val_loss improved from 0.07879 to 0.07850, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0693 - val_loss: 0.0785\n",
      "Epoch 256/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0079\n",
      "Epoch 256: val_loss improved from 0.07850 to 0.07820, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0643 - val_loss: 0.0782\n",
      "Epoch 257/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0087\n",
      "Epoch 257: val_loss improved from 0.07820 to 0.07789, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0721 - val_loss: 0.0779\n",
      "Epoch 258/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0083\n",
      "Epoch 258: val_loss improved from 0.07789 to 0.07759, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0676 - val_loss: 0.0776\n",
      "Epoch 259/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0656\n",
      "Epoch 259: val_loss improved from 0.07759 to 0.07729, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0656 - val_loss: 0.0773\n",
      "Epoch 260/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0614\n",
      "Epoch 260: val_loss improved from 0.07729 to 0.07699, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0614 - val_loss: 0.0770\n",
      "Epoch 261/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0746\n",
      "Epoch 261: val_loss improved from 0.07699 to 0.07669, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0746 - val_loss: 0.0767\n",
      "Epoch 262/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0105\n",
      "Epoch 262: val_loss improved from 0.07669 to 0.07639, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0680 - val_loss: 0.0764\n",
      "Epoch 263/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0700\n",
      "Epoch 263: val_loss improved from 0.07639 to 0.07610, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0700 - val_loss: 0.0761\n",
      "Epoch 264/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0727\n",
      "Epoch 264: val_loss improved from 0.07610 to 0.07581, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0727 - val_loss: 0.0758\n",
      "Epoch 265/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0611\n",
      "Epoch 265: val_loss improved from 0.07581 to 0.07552, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0611 - val_loss: 0.0755\n",
      "Epoch 266/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0672\n",
      "Epoch 266: val_loss improved from 0.07552 to 0.07523, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0672 - val_loss: 0.0752\n",
      "Epoch 267/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0073\n",
      "Epoch 267: val_loss improved from 0.07523 to 0.07494, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0615 - val_loss: 0.0749\n",
      "Epoch 268/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0647\n",
      "Epoch 268: val_loss improved from 0.07494 to 0.07465, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0647 - val_loss: 0.0747\n",
      "Epoch 269/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0663\n",
      "Epoch 269: val_loss improved from 0.07465 to 0.07437, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0663 - val_loss: 0.0744\n",
      "Epoch 270/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0566\n",
      "Epoch 270: val_loss improved from 0.07437 to 0.07409, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0566 - val_loss: 0.0741\n",
      "Epoch 271/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0060\n",
      "Epoch 271: val_loss improved from 0.07409 to 0.07381, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0676 - val_loss: 0.0738\n",
      "Epoch 272/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0631\n",
      "Epoch 272: val_loss improved from 0.07381 to 0.07354, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0631 - val_loss: 0.0735\n",
      "Epoch 273/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0123\n",
      "Epoch 273: val_loss improved from 0.07354 to 0.07327, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0605 - val_loss: 0.0733\n",
      "Epoch 274/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0661\n",
      "Epoch 274: val_loss improved from 0.07327 to 0.07300, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0661 - val_loss: 0.0730\n",
      "Epoch 275/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0071\n",
      "Epoch 275: val_loss improved from 0.07300 to 0.07273, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0583 - val_loss: 0.0727\n",
      "Epoch 276/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0078\n",
      "Epoch 276: val_loss improved from 0.07273 to 0.07246, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0673 - val_loss: 0.0725\n",
      "Epoch 277/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0081\n",
      "Epoch 277: val_loss improved from 0.07246 to 0.07220, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0624 - val_loss: 0.0722\n",
      "Epoch 278/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0698\n",
      "Epoch 278: val_loss improved from 0.07220 to 0.07193, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0698 - val_loss: 0.0719\n",
      "Epoch 279/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0701\n",
      "Epoch 279: val_loss improved from 0.07193 to 0.07167, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0701 - val_loss: 0.0717\n",
      "Epoch 280/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0077\n",
      "Epoch 280: val_loss improved from 0.07167 to 0.07141, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0605 - val_loss: 0.0714\n",
      "Epoch 281/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0645\n",
      "Epoch 281: val_loss improved from 0.07141 to 0.07115, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0645 - val_loss: 0.0711\n",
      "Epoch 282/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0603\n",
      "Epoch 282: val_loss improved from 0.07115 to 0.07089, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0603 - val_loss: 0.0709\n",
      "Epoch 283/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0069\n",
      "Epoch 283: val_loss improved from 0.07089 to 0.07063, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0648 - val_loss: 0.0706\n",
      "Epoch 284/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0606\n",
      "Epoch 284: val_loss improved from 0.07063 to 0.07038, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0606 - val_loss: 0.0704\n",
      "Epoch 285/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0086\n",
      "Epoch 285: val_loss improved from 0.07038 to 0.07013, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0662 - val_loss: 0.0701\n",
      "Epoch 286/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0649\n",
      "Epoch 286: val_loss improved from 0.07013 to 0.06988, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0649 - val_loss: 0.0699\n",
      "Epoch 287/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0608\n",
      "Epoch 287: val_loss improved from 0.06988 to 0.06963, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0608 - val_loss: 0.0696\n",
      "Epoch 288/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0695\n",
      "Epoch 288: val_loss improved from 0.06963 to 0.06938, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0695 - val_loss: 0.0694\n",
      "Epoch 289/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0071\n",
      "Epoch 289: val_loss improved from 0.06938 to 0.06914, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0592 - val_loss: 0.0691\n",
      "Epoch 290/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0733\n",
      "Epoch 290: val_loss improved from 0.06914 to 0.06890, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0733 - val_loss: 0.0689\n",
      "Epoch 291/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0597\n",
      "Epoch 291: val_loss improved from 0.06890 to 0.06867, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0597 - val_loss: 0.0687\n",
      "Epoch 292/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0619\n",
      "Epoch 292: val_loss improved from 0.06867 to 0.06843, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0619 - val_loss: 0.0684\n",
      "Epoch 293/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0071\n",
      "Epoch 293: val_loss improved from 0.06843 to 0.06819, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 0.0719 - val_loss: 0.0682\n",
      "Epoch 294/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0086\n",
      "Epoch 294: val_loss improved from 0.06819 to 0.06795, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0639 - val_loss: 0.0680\n",
      "Epoch 295/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0074\n",
      "Epoch 295: val_loss improved from 0.06795 to 0.06772, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0560 - val_loss: 0.0677\n",
      "Epoch 296/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0596\n",
      "Epoch 296: val_loss improved from 0.06772 to 0.06748, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0596 - val_loss: 0.0675\n",
      "Epoch 297/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0065\n",
      "Epoch 297: val_loss improved from 0.06748 to 0.06725, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0591 - val_loss: 0.0672\n",
      "Epoch 298/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 298: val_loss improved from 0.06725 to 0.06701, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0644 - val_loss: 0.0670\n",
      "Epoch 299/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0089\n",
      "Epoch 299: val_loss improved from 0.06701 to 0.06678, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0667 - val_loss: 0.0668\n",
      "Epoch 300/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0050\n",
      "Epoch 300: val_loss improved from 0.06678 to 0.06654, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0621 - val_loss: 0.0665\n",
      "Epoch 301/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0634\n",
      "Epoch 301: val_loss improved from 0.06654 to 0.06631, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 133ms/step - loss: 0.0634 - val_loss: 0.0663\n",
      "Epoch 302/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0072\n",
      "Epoch 302: val_loss improved from 0.06631 to 0.06608, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0568 - val_loss: 0.0661\n",
      "Epoch 303/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0057\n",
      "Epoch 303: val_loss improved from 0.06608 to 0.06585, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0548 - val_loss: 0.0659\n",
      "Epoch 304/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0056\n",
      "Epoch 304: val_loss improved from 0.06585 to 0.06562, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0625 - val_loss: 0.0656\n",
      "Epoch 305/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0070\n",
      "Epoch 305: val_loss improved from 0.06562 to 0.06539, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0635 - val_loss: 0.0654\n",
      "Epoch 306/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 306: val_loss improved from 0.06539 to 0.06516, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0574 - val_loss: 0.0652\n",
      "Epoch 307/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0582\n",
      "Epoch 307: val_loss improved from 0.06516 to 0.06493, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0582 - val_loss: 0.0649\n",
      "Epoch 308/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0544\n",
      "Epoch 308: val_loss improved from 0.06493 to 0.06470, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0544 - val_loss: 0.0647\n",
      "Epoch 309/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0077\n",
      "Epoch 309: val_loss improved from 0.06470 to 0.06447, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0543 - val_loss: 0.0645\n",
      "Epoch 310/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0490\n",
      "Epoch 310: val_loss improved from 0.06447 to 0.06425, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0490 - val_loss: 0.0642\n",
      "Epoch 311/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0583\n",
      "Epoch 311: val_loss improved from 0.06425 to 0.06402, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0583 - val_loss: 0.0640\n",
      "Epoch 312/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0587\n",
      "Epoch 312: val_loss improved from 0.06402 to 0.06380, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0587 - val_loss: 0.0638\n",
      "Epoch 313/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0530\n",
      "Epoch 313: val_loss improved from 0.06380 to 0.06358, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0530 - val_loss: 0.0636\n",
      "Epoch 314/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0574\n",
      "Epoch 314: val_loss improved from 0.06358 to 0.06336, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0574 - val_loss: 0.0634\n",
      "Epoch 315/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0071\n",
      "Epoch 315: val_loss improved from 0.06336 to 0.06314, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0569 - val_loss: 0.0631\n",
      "Epoch 316/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0563\n",
      "Epoch 316: val_loss improved from 0.06314 to 0.06292, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0563 - val_loss: 0.0629\n",
      "Epoch 317/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0066\n",
      "Epoch 317: val_loss improved from 0.06292 to 0.06270, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0532 - val_loss: 0.0627\n",
      "Epoch 318/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0609\n",
      "Epoch 318: val_loss improved from 0.06270 to 0.06249, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0609 - val_loss: 0.0625\n",
      "Epoch 319/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0557\n",
      "Epoch 319: val_loss improved from 0.06249 to 0.06228, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0557 - val_loss: 0.0623\n",
      "Epoch 320/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0575\n",
      "Epoch 320: val_loss improved from 0.06228 to 0.06207, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0575 - val_loss: 0.0621\n",
      "Epoch 321/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0091\n",
      "Epoch 321: val_loss improved from 0.06207 to 0.06187, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0568 - val_loss: 0.0619\n",
      "Epoch 322/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0069\n",
      "Epoch 322: val_loss improved from 0.06187 to 0.06166, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0536 - val_loss: 0.0617\n",
      "Epoch 323/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0591\n",
      "Epoch 323: val_loss improved from 0.06166 to 0.06145, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0591 - val_loss: 0.0615\n",
      "Epoch 324/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0505\n",
      "Epoch 324: val_loss improved from 0.06145 to 0.06125, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0505 - val_loss: 0.0613\n",
      "Epoch 325/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0549\n",
      "Epoch 325: val_loss improved from 0.06125 to 0.06105, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0549 - val_loss: 0.0611\n",
      "Epoch 326/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0056\n",
      "Epoch 326: val_loss improved from 0.06105 to 0.06086, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0610 - val_loss: 0.0609\n",
      "Epoch 327/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0517\n",
      "Epoch 327: val_loss improved from 0.06086 to 0.06067, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0517 - val_loss: 0.0607\n",
      "Epoch 328/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0536\n",
      "Epoch 328: val_loss improved from 0.06067 to 0.06047, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0536 - val_loss: 0.0605\n",
      "Epoch 329/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0480\n",
      "Epoch 329: val_loss improved from 0.06047 to 0.06028, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0480 - val_loss: 0.0603\n",
      "Epoch 330/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0055\n",
      "Epoch 330: val_loss improved from 0.06028 to 0.06009, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0565 - val_loss: 0.0601\n",
      "Epoch 331/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0510\n",
      "Epoch 331: val_loss improved from 0.06009 to 0.05990, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0510 - val_loss: 0.0599\n",
      "Epoch 332/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0496\n",
      "Epoch 332: val_loss improved from 0.05990 to 0.05971, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0496 - val_loss: 0.0597\n",
      "Epoch 333/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 333: val_loss improved from 0.05971 to 0.05952, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0550 - val_loss: 0.0595\n",
      "Epoch 334/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0462\n",
      "Epoch 334: val_loss improved from 0.05952 to 0.05933, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0462 - val_loss: 0.0593\n",
      "Epoch 335/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0069\n",
      "Epoch 335: val_loss improved from 0.05933 to 0.05914, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0482 - val_loss: 0.0591\n",
      "Epoch 336/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0552\n",
      "Epoch 336: val_loss improved from 0.05914 to 0.05895, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0552 - val_loss: 0.0590\n",
      "Epoch 337/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0070\n",
      "Epoch 337: val_loss improved from 0.05895 to 0.05877, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0548 - val_loss: 0.0588\n",
      "Epoch 338/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0060\n",
      "Epoch 338: val_loss improved from 0.05877 to 0.05858, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0518 - val_loss: 0.0586\n",
      "Epoch 339/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0051\n",
      "Epoch 339: val_loss improved from 0.05858 to 0.05840, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0458 - val_loss: 0.0584\n",
      "Epoch 340/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0484\n",
      "Epoch 340: val_loss improved from 0.05840 to 0.05822, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0484 - val_loss: 0.0582\n",
      "Epoch 341/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0546\n",
      "Epoch 341: val_loss improved from 0.05822 to 0.05804, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0546 - val_loss: 0.0580\n",
      "Epoch 342/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0524\n",
      "Epoch 342: val_loss improved from 0.05804 to 0.05786, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0524 - val_loss: 0.0579\n",
      "Epoch 343/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0498\n",
      "Epoch 343: val_loss improved from 0.05786 to 0.05768, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0498 - val_loss: 0.0577\n",
      "Epoch 344/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0082\n",
      "Epoch 344: val_loss improved from 0.05768 to 0.05750, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0558 - val_loss: 0.0575\n",
      "Epoch 345/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0058\n",
      "Epoch 345: val_loss improved from 0.05750 to 0.05733, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0505 - val_loss: 0.0573\n",
      "Epoch 346/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0475\n",
      "Epoch 346: val_loss improved from 0.05733 to 0.05716, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0475 - val_loss: 0.0572\n",
      "Epoch 347/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0525\n",
      "Epoch 347: val_loss improved from 0.05716 to 0.05699, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0525 - val_loss: 0.0570\n",
      "Epoch 348/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0080\n",
      "Epoch 348: val_loss improved from 0.05699 to 0.05681, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0489 - val_loss: 0.0568\n",
      "Epoch 349/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0457\n",
      "Epoch 349: val_loss improved from 0.05681 to 0.05664, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0457 - val_loss: 0.0566\n",
      "Epoch 350/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0497\n",
      "Epoch 350: val_loss improved from 0.05664 to 0.05648, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0497 - val_loss: 0.0565\n",
      "Epoch 351/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0060\n",
      "Epoch 351: val_loss improved from 0.05648 to 0.05631, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0494 - val_loss: 0.0563\n",
      "Epoch 352/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0055\n",
      "Epoch 352: val_loss improved from 0.05631 to 0.05614, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0519 - val_loss: 0.0561\n",
      "Epoch 353/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0476\n",
      "Epoch 353: val_loss improved from 0.05614 to 0.05597, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0476 - val_loss: 0.0560\n",
      "Epoch 354/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 354: val_loss improved from 0.05597 to 0.05581, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0587 - val_loss: 0.0558\n",
      "Epoch 355/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0048\n",
      "Epoch 355: val_loss improved from 0.05581 to 0.05564, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0397 - val_loss: 0.0556\n",
      "Epoch 356/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0557\n",
      "Epoch 356: val_loss improved from 0.05564 to 0.05548, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0557 - val_loss: 0.0555\n",
      "Epoch 357/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0065\n",
      "Epoch 357: val_loss improved from 0.05548 to 0.05533, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0432 - val_loss: 0.0553\n",
      "Epoch 358/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0520\n",
      "Epoch 358: val_loss improved from 0.05533 to 0.05517, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0520 - val_loss: 0.0552\n",
      "Epoch 359/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0063\n",
      "Epoch 359: val_loss improved from 0.05517 to 0.05502, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0453 - val_loss: 0.0550\n",
      "Epoch 360/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0451\n",
      "Epoch 360: val_loss improved from 0.05502 to 0.05487, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0451 - val_loss: 0.0549\n",
      "Epoch 361/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0067\n",
      "Epoch 361: val_loss improved from 0.05487 to 0.05472, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0437 - val_loss: 0.0547\n",
      "Epoch 362/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0080\n",
      "Epoch 362: val_loss improved from 0.05472 to 0.05457, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0448 - val_loss: 0.0546\n",
      "Epoch 363/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0440\n",
      "Epoch 363: val_loss improved from 0.05457 to 0.05442, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0440 - val_loss: 0.0544\n",
      "Epoch 364/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0470\n",
      "Epoch 364: val_loss improved from 0.05442 to 0.05427, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0470 - val_loss: 0.0543\n",
      "Epoch 365/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0507\n",
      "Epoch 365: val_loss improved from 0.05427 to 0.05412, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0507 - val_loss: 0.0541\n",
      "Epoch 366/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0525\n",
      "Epoch 366: val_loss improved from 0.05412 to 0.05397, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0525 - val_loss: 0.0540\n",
      "Epoch 367/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0066\n",
      "Epoch 367: val_loss improved from 0.05397 to 0.05382, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0626 - val_loss: 0.0538\n",
      "Epoch 368/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0480\n",
      "Epoch 368: val_loss improved from 0.05382 to 0.05368, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0480 - val_loss: 0.0537\n",
      "Epoch 369/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0062\n",
      "Epoch 369: val_loss improved from 0.05368 to 0.05354, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0502 - val_loss: 0.0535\n",
      "Epoch 370/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0494\n",
      "Epoch 370: val_loss improved from 0.05354 to 0.05339, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0494 - val_loss: 0.0534\n",
      "Epoch 371/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0073\n",
      "Epoch 371: val_loss improved from 0.05339 to 0.05325, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0419 - val_loss: 0.0533\n",
      "Epoch 372/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0466\n",
      "Epoch 372: val_loss improved from 0.05325 to 0.05312, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0466 - val_loss: 0.0531\n",
      "Epoch 373/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0075\n",
      "Epoch 373: val_loss improved from 0.05312 to 0.05298, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0513 - val_loss: 0.0530\n",
      "Epoch 374/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0499\n",
      "Epoch 374: val_loss improved from 0.05298 to 0.05284, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0499 - val_loss: 0.0528\n",
      "Epoch 375/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0455\n",
      "Epoch 375: val_loss improved from 0.05284 to 0.05270, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0455 - val_loss: 0.0527\n",
      "Epoch 376/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0067\n",
      "Epoch 376: val_loss improved from 0.05270 to 0.05256, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0465 - val_loss: 0.0526\n",
      "Epoch 377/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0487\n",
      "Epoch 377: val_loss improved from 0.05256 to 0.05243, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0487 - val_loss: 0.0524\n",
      "Epoch 378/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0471\n",
      "Epoch 378: val_loss improved from 0.05243 to 0.05230, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0471 - val_loss: 0.0523\n",
      "Epoch 379/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0443\n",
      "Epoch 379: val_loss improved from 0.05230 to 0.05216, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0443 - val_loss: 0.0522\n",
      "Epoch 380/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0077\n",
      "Epoch 380: val_loss improved from 0.05216 to 0.05203, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0462 - val_loss: 0.0520\n",
      "Epoch 381/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0062\n",
      "Epoch 381: val_loss improved from 0.05203 to 0.05190, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0484 - val_loss: 0.0519\n",
      "Epoch 382/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0062\n",
      "Epoch 382: val_loss improved from 0.05190 to 0.05177, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0520 - val_loss: 0.0518\n",
      "Epoch 383/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0077\n",
      "Epoch 383: val_loss improved from 0.05177 to 0.05164, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0424 - val_loss: 0.0516\n",
      "Epoch 384/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0415\n",
      "Epoch 384: val_loss improved from 0.05164 to 0.05152, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0415 - val_loss: 0.0515\n",
      "Epoch 385/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0465\n",
      "Epoch 385: val_loss improved from 0.05152 to 0.05139, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0465 - val_loss: 0.0514\n",
      "Epoch 386/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0464\n",
      "Epoch 386: val_loss improved from 0.05139 to 0.05126, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0464 - val_loss: 0.0513\n",
      "Epoch 387/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0066\n",
      "Epoch 387: val_loss improved from 0.05126 to 0.05113, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0491 - val_loss: 0.0511\n",
      "Epoch 388/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0442\n",
      "Epoch 388: val_loss improved from 0.05113 to 0.05100, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0442 - val_loss: 0.0510\n",
      "Epoch 389/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0378\n",
      "Epoch 389: val_loss improved from 0.05100 to 0.05088, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0378 - val_loss: 0.0509\n",
      "Epoch 390/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0405\n",
      "Epoch 390: val_loss improved from 0.05088 to 0.05075, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0405 - val_loss: 0.0507\n",
      "Epoch 391/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0437\n",
      "Epoch 391: val_loss improved from 0.05075 to 0.05062, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0437 - val_loss: 0.0506\n",
      "Epoch 392/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0473\n",
      "Epoch 392: val_loss improved from 0.05062 to 0.05050, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0473 - val_loss: 0.0505\n",
      "Epoch 393/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0465\n",
      "Epoch 393: val_loss improved from 0.05050 to 0.05037, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0465 - val_loss: 0.0504\n",
      "Epoch 394/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0066\n",
      "Epoch 394: val_loss improved from 0.05037 to 0.05025, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0437 - val_loss: 0.0502\n",
      "Epoch 395/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0456\n",
      "Epoch 395: val_loss improved from 0.05025 to 0.05012, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0456 - val_loss: 0.0501\n",
      "Epoch 396/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 396: val_loss improved from 0.05012 to 0.05000, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0450 - val_loss: 0.0500\n",
      "Epoch 397/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0432\n",
      "Epoch 397: val_loss improved from 0.05000 to 0.04987, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0432 - val_loss: 0.0499\n",
      "Epoch 398/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0095\n",
      "Epoch 398: val_loss improved from 0.04987 to 0.04975, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0475 - val_loss: 0.0497\n",
      "Epoch 399/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0068\n",
      "Epoch 399: val_loss improved from 0.04975 to 0.04962, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0415 - val_loss: 0.0496\n",
      "Epoch 400/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0436\n",
      "Epoch 400: val_loss improved from 0.04962 to 0.04950, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0436 - val_loss: 0.0495\n",
      "Epoch 401/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0451\n",
      "Epoch 401: val_loss improved from 0.04950 to 0.04938, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0451 - val_loss: 0.0494\n",
      "Epoch 402/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0077\n",
      "Epoch 402: val_loss improved from 0.04938 to 0.04927, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0491 - val_loss: 0.0493\n",
      "Epoch 403/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0061\n",
      "Epoch 403: val_loss improved from 0.04927 to 0.04915, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0386 - val_loss: 0.0491\n",
      "Epoch 404/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0062\n",
      "Epoch 404: val_loss improved from 0.04915 to 0.04903, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0480 - val_loss: 0.0490\n",
      "Epoch 405/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0105\n",
      "Epoch 405: val_loss improved from 0.04903 to 0.04892, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0415 - val_loss: 0.0489\n",
      "Epoch 406/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0076\n",
      "Epoch 406: val_loss improved from 0.04892 to 0.04880, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0455 - val_loss: 0.0488\n",
      "Epoch 407/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0067\n",
      "Epoch 407: val_loss improved from 0.04880 to 0.04869, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0445 - val_loss: 0.0487\n",
      "Epoch 408/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0086\n",
      "Epoch 408: val_loss improved from 0.04869 to 0.04858, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0470 - val_loss: 0.0486\n",
      "Epoch 409/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0092\n",
      "Epoch 409: val_loss improved from 0.04858 to 0.04847, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0378 - val_loss: 0.0485\n",
      "Epoch 410/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0438\n",
      "Epoch 410: val_loss improved from 0.04847 to 0.04836, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0438 - val_loss: 0.0484\n",
      "Epoch 411/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0076\n",
      "Epoch 411: val_loss improved from 0.04836 to 0.04825, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0394 - val_loss: 0.0482\n",
      "Epoch 412/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0423\n",
      "Epoch 412: val_loss improved from 0.04825 to 0.04814, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0423 - val_loss: 0.0481\n",
      "Epoch 413/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0424\n",
      "Epoch 413: val_loss improved from 0.04814 to 0.04803, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0424 - val_loss: 0.0480\n",
      "Epoch 414/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0070\n",
      "Epoch 414: val_loss improved from 0.04803 to 0.04792, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0423 - val_loss: 0.0479\n",
      "Epoch 415/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0437\n",
      "Epoch 415: val_loss improved from 0.04792 to 0.04782, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0437 - val_loss: 0.0478\n",
      "Epoch 416/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0077\n",
      "Epoch 416: val_loss improved from 0.04782 to 0.04771, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0329 - val_loss: 0.0477\n",
      "Epoch 417/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0072\n",
      "Epoch 417: val_loss improved from 0.04771 to 0.04761, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0398 - val_loss: 0.0476\n",
      "Epoch 418/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0064\n",
      "Epoch 418: val_loss improved from 0.04761 to 0.04751, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0451 - val_loss: 0.0475\n",
      "Epoch 419/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0489\n",
      "Epoch 419: val_loss improved from 0.04751 to 0.04740, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0489 - val_loss: 0.0474\n",
      "Epoch 420/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0049\n",
      "Epoch 420: val_loss improved from 0.04740 to 0.04730, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0425 - val_loss: 0.0473\n",
      "Epoch 421/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0075\n",
      "Epoch 421: val_loss improved from 0.04730 to 0.04720, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0494 - val_loss: 0.0472\n",
      "Epoch 422/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0074\n",
      "Epoch 422: val_loss improved from 0.04720 to 0.04710, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0483 - val_loss: 0.0471\n",
      "Epoch 423/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0474\n",
      "Epoch 423: val_loss improved from 0.04710 to 0.04700, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0474 - val_loss: 0.0470\n",
      "Epoch 424/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0063\n",
      "Epoch 424: val_loss improved from 0.04700 to 0.04690, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0457 - val_loss: 0.0469\n",
      "Epoch 425/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0457\n",
      "Epoch 425: val_loss improved from 0.04690 to 0.04680, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0457 - val_loss: 0.0468\n",
      "Epoch 426/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0057\n",
      "Epoch 426: val_loss improved from 0.04680 to 0.04670, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0331 - val_loss: 0.0467\n",
      "Epoch 427/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0453\n",
      "Epoch 427: val_loss improved from 0.04670 to 0.04660, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0453 - val_loss: 0.0466\n",
      "Epoch 428/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0104\n",
      "Epoch 428: val_loss improved from 0.04660 to 0.04650, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0438 - val_loss: 0.0465\n",
      "Epoch 429/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0067\n",
      "Epoch 429: val_loss improved from 0.04650 to 0.04640, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0405 - val_loss: 0.0464\n",
      "Epoch 430/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0065\n",
      "Epoch 430: val_loss improved from 0.04640 to 0.04631, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0471 - val_loss: 0.0463\n",
      "Epoch 431/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0497\n",
      "Epoch 431: val_loss improved from 0.04631 to 0.04621, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0497 - val_loss: 0.0462\n",
      "Epoch 432/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0413\n",
      "Epoch 432: val_loss improved from 0.04621 to 0.04612, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0413 - val_loss: 0.0461\n",
      "Epoch 433/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0403\n",
      "Epoch 433: val_loss improved from 0.04612 to 0.04602, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0403 - val_loss: 0.0460\n",
      "Epoch 434/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0081\n",
      "Epoch 434: val_loss improved from 0.04602 to 0.04593, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0376 - val_loss: 0.0459\n",
      "Epoch 435/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0414\n",
      "Epoch 435: val_loss improved from 0.04593 to 0.04584, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0414 - val_loss: 0.0458\n",
      "Epoch 436/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0396\n",
      "Epoch 436: val_loss improved from 0.04584 to 0.04575, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0396 - val_loss: 0.0458\n",
      "Epoch 437/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0409\n",
      "Epoch 437: val_loss improved from 0.04575 to 0.04566, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0409 - val_loss: 0.0457\n",
      "Epoch 438/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0055\n",
      "Epoch 438: val_loss improved from 0.04566 to 0.04557, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0415 - val_loss: 0.0456\n",
      "Epoch 439/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0105\n",
      "Epoch 439: val_loss improved from 0.04557 to 0.04549, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0381 - val_loss: 0.0455\n",
      "Epoch 440/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0077\n",
      "Epoch 440: val_loss improved from 0.04549 to 0.04540, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0395 - val_loss: 0.0454\n",
      "Epoch 441/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0067\n",
      "Epoch 441: val_loss improved from 0.04540 to 0.04531, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0387 - val_loss: 0.0453\n",
      "Epoch 442/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0511\n",
      "Epoch 442: val_loss improved from 0.04531 to 0.04522, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0511 - val_loss: 0.0452\n",
      "Epoch 443/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0418\n",
      "Epoch 443: val_loss improved from 0.04522 to 0.04514, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0418 - val_loss: 0.0451\n",
      "Epoch 444/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 444: val_loss improved from 0.04514 to 0.04505, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0380 - val_loss: 0.0451\n",
      "Epoch 445/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0064\n",
      "Epoch 445: val_loss improved from 0.04505 to 0.04496, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 0.0346 - val_loss: 0.0450\n",
      "Epoch 446/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0461\n",
      "Epoch 446: val_loss improved from 0.04496 to 0.04488, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0461 - val_loss: 0.0449\n",
      "Epoch 447/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0375\n",
      "Epoch 447: val_loss improved from 0.04488 to 0.04479, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0375 - val_loss: 0.0448\n",
      "Epoch 448/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0330\n",
      "Epoch 448: val_loss improved from 0.04479 to 0.04471, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0330 - val_loss: 0.0447\n",
      "Epoch 449/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0082\n",
      "Epoch 449: val_loss improved from 0.04471 to 0.04463, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0397 - val_loss: 0.0446\n",
      "Epoch 450/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0361\n",
      "Epoch 450: val_loss improved from 0.04463 to 0.04454, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0361 - val_loss: 0.0445\n",
      "Epoch 451/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0076\n",
      "Epoch 451: val_loss improved from 0.04454 to 0.04446, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0382 - val_loss: 0.0445\n",
      "Epoch 452/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0393\n",
      "Epoch 452: val_loss improved from 0.04446 to 0.04438, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0393 - val_loss: 0.0444\n",
      "Epoch 453/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0346\n",
      "Epoch 453: val_loss improved from 0.04438 to 0.04430, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0346 - val_loss: 0.0443\n",
      "Epoch 454/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0428\n",
      "Epoch 454: val_loss improved from 0.04430 to 0.04421, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0428 - val_loss: 0.0442\n",
      "Epoch 455/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0072\n",
      "Epoch 455: val_loss improved from 0.04421 to 0.04413, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0401 - val_loss: 0.0441\n",
      "Epoch 456/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0099\n",
      "Epoch 456: val_loss improved from 0.04413 to 0.04404, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0394 - val_loss: 0.0440\n",
      "Epoch 457/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0440\n",
      "Epoch 457: val_loss improved from 0.04404 to 0.04396, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0440 - val_loss: 0.0440\n",
      "Epoch 458/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0089\n",
      "Epoch 458: val_loss improved from 0.04396 to 0.04388, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0365 - val_loss: 0.0439\n",
      "Epoch 459/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0358\n",
      "Epoch 459: val_loss improved from 0.04388 to 0.04379, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0358 - val_loss: 0.0438\n",
      "Epoch 460/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0395\n",
      "Epoch 460: val_loss improved from 0.04379 to 0.04371, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0395 - val_loss: 0.0437\n",
      "Epoch 461/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0355\n",
      "Epoch 461: val_loss improved from 0.04371 to 0.04363, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0355 - val_loss: 0.0436\n",
      "Epoch 462/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0316\n",
      "Epoch 462: val_loss improved from 0.04363 to 0.04355, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0316 - val_loss: 0.0435\n",
      "Epoch 463/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0386\n",
      "Epoch 463: val_loss improved from 0.04355 to 0.04347, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0386 - val_loss: 0.0435\n",
      "Epoch 464/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0359\n",
      "Epoch 464: val_loss improved from 0.04347 to 0.04338, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0359 - val_loss: 0.0434\n",
      "Epoch 465/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0363\n",
      "Epoch 465: val_loss improved from 0.04338 to 0.04330, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0363 - val_loss: 0.0433\n",
      "Epoch 466/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0432\n",
      "Epoch 466: val_loss improved from 0.04330 to 0.04322, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0432 - val_loss: 0.0432\n",
      "Epoch 467/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0345\n",
      "Epoch 467: val_loss improved from 0.04322 to 0.04314, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0345 - val_loss: 0.0431\n",
      "Epoch 468/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0431\n",
      "Epoch 468: val_loss improved from 0.04314 to 0.04307, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0431 - val_loss: 0.0431\n",
      "Epoch 469/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0407\n",
      "Epoch 469: val_loss improved from 0.04307 to 0.04299, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0407 - val_loss: 0.0430\n",
      "Epoch 470/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0455\n",
      "Epoch 470: val_loss improved from 0.04299 to 0.04291, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0455 - val_loss: 0.0429\n",
      "Epoch 471/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0403\n",
      "Epoch 471: val_loss improved from 0.04291 to 0.04284, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0403 - val_loss: 0.0428\n",
      "Epoch 472/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0368\n",
      "Epoch 472: val_loss improved from 0.04284 to 0.04277, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0368 - val_loss: 0.0428\n",
      "Epoch 473/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0393\n",
      "Epoch 473: val_loss improved from 0.04277 to 0.04270, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0393 - val_loss: 0.0427\n",
      "Epoch 474/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0403\n",
      "Epoch 474: val_loss improved from 0.04270 to 0.04263, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0403 - val_loss: 0.0426\n",
      "Epoch 475/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0442\n",
      "Epoch 475: val_loss improved from 0.04263 to 0.04257, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0442 - val_loss: 0.0426\n",
      "Epoch 476/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0085\n",
      "Epoch 476: val_loss improved from 0.04257 to 0.04250, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0363 - val_loss: 0.0425\n",
      "Epoch 477/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0374\n",
      "Epoch 477: val_loss improved from 0.04250 to 0.04243, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0374 - val_loss: 0.0424\n",
      "Epoch 478/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0083\n",
      "Epoch 478: val_loss improved from 0.04243 to 0.04236, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0310 - val_loss: 0.0424\n",
      "Epoch 479/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0400\n",
      "Epoch 479: val_loss improved from 0.04236 to 0.04229, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0400 - val_loss: 0.0423\n",
      "Epoch 480/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0403\n",
      "Epoch 480: val_loss improved from 0.04229 to 0.04222, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0403 - val_loss: 0.0422\n",
      "Epoch 481/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0093\n",
      "Epoch 481: val_loss improved from 0.04222 to 0.04215, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0453 - val_loss: 0.0422\n",
      "Epoch 482/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0437\n",
      "Epoch 482: val_loss improved from 0.04215 to 0.04209, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0437 - val_loss: 0.0421\n",
      "Epoch 483/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0089\n",
      "Epoch 483: val_loss improved from 0.04209 to 0.04202, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0464 - val_loss: 0.0420\n",
      "Epoch 484/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0113\n",
      "Epoch 484: val_loss improved from 0.04202 to 0.04195, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0475 - val_loss: 0.0419\n",
      "Epoch 485/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0395\n",
      "Epoch 485: val_loss improved from 0.04195 to 0.04188, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0395 - val_loss: 0.0419\n",
      "Epoch 486/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 486: val_loss improved from 0.04188 to 0.04181, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0335 - val_loss: 0.0418\n",
      "Epoch 487/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0111\n",
      "Epoch 487: val_loss improved from 0.04181 to 0.04174, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0390 - val_loss: 0.0417\n",
      "Epoch 488/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0359\n",
      "Epoch 488: val_loss improved from 0.04174 to 0.04167, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0359 - val_loss: 0.0417\n",
      "Epoch 489/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0153\n",
      "Epoch 489: val_loss improved from 0.04167 to 0.04160, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0384 - val_loss: 0.0416\n",
      "Epoch 490/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0394\n",
      "Epoch 490: val_loss improved from 0.04160 to 0.04154, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0394 - val_loss: 0.0415\n",
      "Epoch 491/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0392\n",
      "Epoch 491: val_loss improved from 0.04154 to 0.04147, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0392 - val_loss: 0.0415\n",
      "Epoch 492/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0064\n",
      "Epoch 492: val_loss improved from 0.04147 to 0.04140, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0277 - val_loss: 0.0414\n",
      "Epoch 493/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0086\n",
      "Epoch 493: val_loss improved from 0.04140 to 0.04134, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0359 - val_loss: 0.0413\n",
      "Epoch 494/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0090\n",
      "Epoch 494: val_loss improved from 0.04134 to 0.04127, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0376 - val_loss: 0.0413\n",
      "Epoch 495/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0359\n",
      "Epoch 495: val_loss improved from 0.04127 to 0.04121, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0359 - val_loss: 0.0412\n",
      "Epoch 496/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0091\n",
      "Epoch 496: val_loss improved from 0.04121 to 0.04115, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0386 - val_loss: 0.0411\n",
      "Epoch 497/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0355\n",
      "Epoch 497: val_loss improved from 0.04115 to 0.04108, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0355 - val_loss: 0.0411\n",
      "Epoch 498/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0100\n",
      "Epoch 498: val_loss improved from 0.04108 to 0.04102, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0360 - val_loss: 0.0410\n",
      "Epoch 499/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0085\n",
      "Epoch 499: val_loss improved from 0.04102 to 0.04096, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0402 - val_loss: 0.0410\n",
      "Epoch 500/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0372\n",
      "Epoch 500: val_loss improved from 0.04096 to 0.04090, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0372 - val_loss: 0.0409\n",
      "Epoch 501/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0330\n",
      "Epoch 501: val_loss improved from 0.04090 to 0.04083, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0330 - val_loss: 0.0408\n",
      "Epoch 502/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0091\n",
      "Epoch 502: val_loss improved from 0.04083 to 0.04077, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0343 - val_loss: 0.0408\n",
      "Epoch 503/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0406\n",
      "Epoch 503: val_loss improved from 0.04077 to 0.04071, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0406 - val_loss: 0.0407\n",
      "Epoch 504/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0358\n",
      "Epoch 504: val_loss improved from 0.04071 to 0.04064, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0358 - val_loss: 0.0406\n",
      "Epoch 505/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0337\n",
      "Epoch 505: val_loss improved from 0.04064 to 0.04058, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0337 - val_loss: 0.0406\n",
      "Epoch 506/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0404\n",
      "Epoch 506: val_loss improved from 0.04058 to 0.04052, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0404 - val_loss: 0.0405\n",
      "Epoch 507/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0097\n",
      "Epoch 507: val_loss improved from 0.04052 to 0.04045, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0344 - val_loss: 0.0405\n",
      "Epoch 508/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0385\n",
      "Epoch 508: val_loss improved from 0.04045 to 0.04039, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0385 - val_loss: 0.0404\n",
      "Epoch 509/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0082\n",
      "Epoch 509: val_loss improved from 0.04039 to 0.04034, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0337 - val_loss: 0.0403\n",
      "Epoch 510/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0377\n",
      "Epoch 510: val_loss improved from 0.04034 to 0.04028, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0377 - val_loss: 0.0403\n",
      "Epoch 511/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0092\n",
      "Epoch 511: val_loss improved from 0.04028 to 0.04022, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0323 - val_loss: 0.0402\n",
      "Epoch 512/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0319\n",
      "Epoch 512: val_loss improved from 0.04022 to 0.04016, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0319 - val_loss: 0.0402\n",
      "Epoch 513/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0326\n",
      "Epoch 513: val_loss improved from 0.04016 to 0.04010, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0326 - val_loss: 0.0401\n",
      "Epoch 514/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0346\n",
      "Epoch 514: val_loss improved from 0.04010 to 0.04004, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0346 - val_loss: 0.0400\n",
      "Epoch 515/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0097\n",
      "Epoch 515: val_loss improved from 0.04004 to 0.03998, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0320 - val_loss: 0.0400\n",
      "Epoch 516/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0356\n",
      "Epoch 516: val_loss improved from 0.03998 to 0.03992, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0356 - val_loss: 0.0399\n",
      "Epoch 517/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0089\n",
      "Epoch 517: val_loss improved from 0.03992 to 0.03986, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0382 - val_loss: 0.0399\n",
      "Epoch 518/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0343\n",
      "Epoch 518: val_loss improved from 0.03986 to 0.03980, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0343 - val_loss: 0.0398\n",
      "Epoch 519/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0369\n",
      "Epoch 519: val_loss improved from 0.03980 to 0.03974, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0369 - val_loss: 0.0397\n",
      "Epoch 520/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0088\n",
      "Epoch 520: val_loss improved from 0.03974 to 0.03968, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0333 - val_loss: 0.0397\n",
      "Epoch 521/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0083\n",
      "Epoch 521: val_loss improved from 0.03968 to 0.03962, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0300 - val_loss: 0.0396\n",
      "Epoch 522/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0100\n",
      "Epoch 522: val_loss improved from 0.03962 to 0.03956, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0367 - val_loss: 0.0396\n",
      "Epoch 523/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0442\n",
      "Epoch 523: val_loss improved from 0.03956 to 0.03950, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0442 - val_loss: 0.0395\n",
      "Epoch 524/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0297\n",
      "Epoch 524: val_loss improved from 0.03950 to 0.03945, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0297 - val_loss: 0.0394\n",
      "Epoch 525/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0096\n",
      "Epoch 525: val_loss improved from 0.03945 to 0.03939, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0262 - val_loss: 0.0394\n",
      "Epoch 526/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0078\n",
      "Epoch 526: val_loss improved from 0.03939 to 0.03933, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0310 - val_loss: 0.0393\n",
      "Epoch 527/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0344\n",
      "Epoch 527: val_loss improved from 0.03933 to 0.03928, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0344 - val_loss: 0.0393\n",
      "Epoch 528/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0363\n",
      "Epoch 528: val_loss improved from 0.03928 to 0.03923, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0363 - val_loss: 0.0392\n",
      "Epoch 529/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0100\n",
      "Epoch 529: val_loss improved from 0.03923 to 0.03917, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0392 - val_loss: 0.0392\n",
      "Epoch 530/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0294\n",
      "Epoch 530: val_loss improved from 0.03917 to 0.03912, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0294 - val_loss: 0.0391\n",
      "Epoch 531/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0329\n",
      "Epoch 531: val_loss improved from 0.03912 to 0.03906, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0329 - val_loss: 0.0391\n",
      "Epoch 532/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0315\n",
      "Epoch 532: val_loss improved from 0.03906 to 0.03901, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0315 - val_loss: 0.0390\n",
      "Epoch 533/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0098\n",
      "Epoch 533: val_loss improved from 0.03901 to 0.03895, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0317 - val_loss: 0.0390\n",
      "Epoch 534/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0404\n",
      "Epoch 534: val_loss improved from 0.03895 to 0.03890, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0404 - val_loss: 0.0389\n",
      "Epoch 535/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0090\n",
      "Epoch 535: val_loss improved from 0.03890 to 0.03885, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0368 - val_loss: 0.0388\n",
      "Epoch 536/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0357\n",
      "Epoch 536: val_loss improved from 0.03885 to 0.03880, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0357 - val_loss: 0.0388\n",
      "Epoch 537/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0336\n",
      "Epoch 537: val_loss improved from 0.03880 to 0.03874, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0336 - val_loss: 0.0387\n",
      "Epoch 538/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0325\n",
      "Epoch 538: val_loss improved from 0.03874 to 0.03869, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0325 - val_loss: 0.0387\n",
      "Epoch 539/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0273\n",
      "Epoch 539: val_loss improved from 0.03869 to 0.03864, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0273 - val_loss: 0.0386\n",
      "Epoch 540/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0362\n",
      "Epoch 540: val_loss improved from 0.03864 to 0.03859, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0362 - val_loss: 0.0386\n",
      "Epoch 541/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0319\n",
      "Epoch 541: val_loss improved from 0.03859 to 0.03854, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0319 - val_loss: 0.0385\n",
      "Epoch 542/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0116\n",
      "Epoch 542: val_loss improved from 0.03854 to 0.03849, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0382 - val_loss: 0.0385\n",
      "Epoch 543/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0331\n",
      "Epoch 543: val_loss improved from 0.03849 to 0.03843, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0331 - val_loss: 0.0384\n",
      "Epoch 544/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0114\n",
      "Epoch 544: val_loss improved from 0.03843 to 0.03838, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0349 - val_loss: 0.0384\n",
      "Epoch 545/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0455\n",
      "Epoch 545: val_loss improved from 0.03838 to 0.03833, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0455 - val_loss: 0.0383\n",
      "Epoch 546/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0393\n",
      "Epoch 546: val_loss improved from 0.03833 to 0.03828, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0393 - val_loss: 0.0383\n",
      "Epoch 547/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0278\n",
      "Epoch 547: val_loss improved from 0.03828 to 0.03823, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0278 - val_loss: 0.0382\n",
      "Epoch 548/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0350\n",
      "Epoch 548: val_loss improved from 0.03823 to 0.03818, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0350 - val_loss: 0.0382\n",
      "Epoch 549/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0126\n",
      "Epoch 549: val_loss improved from 0.03818 to 0.03813, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0333 - val_loss: 0.0381\n",
      "Epoch 550/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 550: val_loss improved from 0.03813 to 0.03808, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0351 - val_loss: 0.0381\n",
      "Epoch 551/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0363\n",
      "Epoch 551: val_loss improved from 0.03808 to 0.03803, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0363 - val_loss: 0.0380\n",
      "Epoch 552/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0082\n",
      "Epoch 552: val_loss improved from 0.03803 to 0.03799, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0279 - val_loss: 0.0380\n",
      "Epoch 553/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0325\n",
      "Epoch 553: val_loss improved from 0.03799 to 0.03794, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0325 - val_loss: 0.0379\n",
      "Epoch 554/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0324\n",
      "Epoch 554: val_loss improved from 0.03794 to 0.03789, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0324 - val_loss: 0.0379\n",
      "Epoch 555/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0128\n",
      "Epoch 555: val_loss improved from 0.03789 to 0.03784, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0345 - val_loss: 0.0378\n",
      "Epoch 556/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0114\n",
      "Epoch 556: val_loss improved from 0.03784 to 0.03779, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0375 - val_loss: 0.0378\n",
      "Epoch 557/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0374\n",
      "Epoch 557: val_loss improved from 0.03779 to 0.03774, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0374 - val_loss: 0.0377\n",
      "Epoch 558/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0404\n",
      "Epoch 558: val_loss improved from 0.03774 to 0.03769, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0404 - val_loss: 0.0377\n",
      "Epoch 559/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0357\n",
      "Epoch 559: val_loss improved from 0.03769 to 0.03764, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0357 - val_loss: 0.0376\n",
      "Epoch 560/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 560: val_loss improved from 0.03764 to 0.03760, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0317 - val_loss: 0.0376\n",
      "Epoch 561/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0322\n",
      "Epoch 561: val_loss improved from 0.03760 to 0.03755, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0322 - val_loss: 0.0375\n",
      "Epoch 562/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0317\n",
      "Epoch 562: val_loss improved from 0.03755 to 0.03750, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0317 - val_loss: 0.0375\n",
      "Epoch 563/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0111\n",
      "Epoch 563: val_loss improved from 0.03750 to 0.03745, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 148ms/step - loss: 0.0371 - val_loss: 0.0375\n",
      "Epoch 564/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0396\n",
      "Epoch 564: val_loss improved from 0.03745 to 0.03741, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 128ms/step - loss: 0.0396 - val_loss: 0.0374\n",
      "Epoch 565/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0290\n",
      "Epoch 565: val_loss improved from 0.03741 to 0.03736, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0290 - val_loss: 0.0374\n",
      "Epoch 566/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0366\n",
      "Epoch 566: val_loss improved from 0.03736 to 0.03732, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0366 - val_loss: 0.0373\n",
      "Epoch 567/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0076\n",
      "Epoch 567: val_loss improved from 0.03732 to 0.03728, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0332 - val_loss: 0.0373\n",
      "Epoch 568/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0444\n",
      "Epoch 568: val_loss improved from 0.03728 to 0.03723, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0444 - val_loss: 0.0372\n",
      "Epoch 569/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0366\n",
      "Epoch 569: val_loss improved from 0.03723 to 0.03719, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0366 - val_loss: 0.0372\n",
      "Epoch 570/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0338\n",
      "Epoch 570: val_loss improved from 0.03719 to 0.03715, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0338 - val_loss: 0.0371\n",
      "Epoch 571/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0292\n",
      "Epoch 571: val_loss improved from 0.03715 to 0.03710, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0292 - val_loss: 0.0371\n",
      "Epoch 572/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0410\n",
      "Epoch 572: val_loss improved from 0.03710 to 0.03706, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0410 - val_loss: 0.0371\n",
      "Epoch 573/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0310\n",
      "Epoch 573: val_loss improved from 0.03706 to 0.03701, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0310 - val_loss: 0.0370\n",
      "Epoch 574/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0300\n",
      "Epoch 574: val_loss improved from 0.03701 to 0.03697, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0300 - val_loss: 0.0370\n",
      "Epoch 575/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0359\n",
      "Epoch 575: val_loss improved from 0.03697 to 0.03693, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0359 - val_loss: 0.0369\n",
      "Epoch 576/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0148\n",
      "Epoch 576: val_loss improved from 0.03693 to 0.03688, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0390 - val_loss: 0.0369\n",
      "Epoch 577/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0159\n",
      "Epoch 577: val_loss improved from 0.03688 to 0.03684, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0305 - val_loss: 0.0368\n",
      "Epoch 578/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0388\n",
      "Epoch 578: val_loss improved from 0.03684 to 0.03679, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0388 - val_loss: 0.0368\n",
      "Epoch 579/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0398\n",
      "Epoch 579: val_loss improved from 0.03679 to 0.03675, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0398 - val_loss: 0.0367\n",
      "Epoch 580/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0369\n",
      "Epoch 580: val_loss improved from 0.03675 to 0.03670, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0369 - val_loss: 0.0367\n",
      "Epoch 581/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0366\n",
      "Epoch 581: val_loss improved from 0.03670 to 0.03666, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0366 - val_loss: 0.0367\n",
      "Epoch 582/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0382\n",
      "Epoch 582: val_loss improved from 0.03666 to 0.03661, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0382 - val_loss: 0.0366\n",
      "Epoch 583/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0334\n",
      "Epoch 583: val_loss improved from 0.03661 to 0.03657, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0334 - val_loss: 0.0366\n",
      "Epoch 584/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0315\n",
      "Epoch 584: val_loss improved from 0.03657 to 0.03653, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0315 - val_loss: 0.0365\n",
      "Epoch 585/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0355\n",
      "Epoch 585: val_loss improved from 0.03653 to 0.03649, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0355 - val_loss: 0.0365\n",
      "Epoch 586/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0318\n",
      "Epoch 586: val_loss improved from 0.03649 to 0.03645, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0318 - val_loss: 0.0364\n",
      "Epoch 587/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0359\n",
      "Epoch 587: val_loss improved from 0.03645 to 0.03641, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0359 - val_loss: 0.0364\n",
      "Epoch 588/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0284\n",
      "Epoch 588: val_loss improved from 0.03641 to 0.03636, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0284 - val_loss: 0.0364\n",
      "Epoch 589/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0335\n",
      "Epoch 589: val_loss improved from 0.03636 to 0.03632, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0335 - val_loss: 0.0363\n",
      "Epoch 590/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0368\n",
      "Epoch 590: val_loss improved from 0.03632 to 0.03628, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0368 - val_loss: 0.0363\n",
      "Epoch 591/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0107\n",
      "Epoch 591: val_loss improved from 0.03628 to 0.03624, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0373 - val_loss: 0.0362\n",
      "Epoch 592/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0290\n",
      "Epoch 592: val_loss improved from 0.03624 to 0.03619, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0290 - val_loss: 0.0362\n",
      "Epoch 593/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0363\n",
      "Epoch 593: val_loss improved from 0.03619 to 0.03615, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0363 - val_loss: 0.0361\n",
      "Epoch 594/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0276\n",
      "Epoch 594: val_loss improved from 0.03615 to 0.03611, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 0.0276 - val_loss: 0.0361\n",
      "Epoch 595/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0355\n",
      "Epoch 595: val_loss improved from 0.03611 to 0.03606, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0355 - val_loss: 0.0361\n",
      "Epoch 596/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0324\n",
      "Epoch 596: val_loss improved from 0.03606 to 0.03602, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0324 - val_loss: 0.0360\n",
      "Epoch 597/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0140\n",
      "Epoch 597: val_loss improved from 0.03602 to 0.03598, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0316 - val_loss: 0.0360\n",
      "Epoch 598/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0305\n",
      "Epoch 598: val_loss improved from 0.03598 to 0.03593, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 132ms/step - loss: 0.0305 - val_loss: 0.0359\n",
      "Epoch 599/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0459\n",
      "Epoch 599: val_loss improved from 0.03593 to 0.03589, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0459 - val_loss: 0.0359\n",
      "Epoch 600/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0267\n",
      "Epoch 600: val_loss improved from 0.03589 to 0.03585, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0267 - val_loss: 0.0359\n",
      "Epoch 601/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0291\n",
      "Epoch 601: val_loss improved from 0.03585 to 0.03581, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0291 - val_loss: 0.0358\n",
      "Epoch 602/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0308\n",
      "Epoch 602: val_loss improved from 0.03581 to 0.03577, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0308 - val_loss: 0.0358\n",
      "Epoch 603/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0156\n",
      "Epoch 603: val_loss improved from 0.03577 to 0.03573, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0268 - val_loss: 0.0357\n",
      "Epoch 604/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0336\n",
      "Epoch 604: val_loss improved from 0.03573 to 0.03569, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0336 - val_loss: 0.0357\n",
      "Epoch 605/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0353\n",
      "Epoch 605: val_loss improved from 0.03569 to 0.03565, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0353 - val_loss: 0.0356\n",
      "Epoch 606/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0292\n",
      "Epoch 606: val_loss improved from 0.03565 to 0.03561, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0292 - val_loss: 0.0356\n",
      "Epoch 607/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0346\n",
      "Epoch 607: val_loss improved from 0.03561 to 0.03557, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0346 - val_loss: 0.0356\n",
      "Epoch 608/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0276\n",
      "Epoch 608: val_loss improved from 0.03557 to 0.03553, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 130ms/step - loss: 0.0276 - val_loss: 0.0355\n",
      "Epoch 609/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0150\n",
      "Epoch 609: val_loss improved from 0.03553 to 0.03549, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0340 - val_loss: 0.0355\n",
      "Epoch 610/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0338\n",
      "Epoch 610: val_loss improved from 0.03549 to 0.03545, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 0.0338 - val_loss: 0.0354\n",
      "Epoch 611/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0312\n",
      "Epoch 611: val_loss improved from 0.03545 to 0.03541, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0312 - val_loss: 0.0354\n",
      "Epoch 612/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0324\n",
      "Epoch 612: val_loss improved from 0.03541 to 0.03537, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0324 - val_loss: 0.0354\n",
      "Epoch 613/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0135\n",
      "Epoch 613: val_loss improved from 0.03537 to 0.03533, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 0.0426 - val_loss: 0.0353\n",
      "Epoch 614/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0300\n",
      "Epoch 614: val_loss improved from 0.03533 to 0.03529, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 134ms/step - loss: 0.0300 - val_loss: 0.0353\n",
      "Epoch 615/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0320\n",
      "Epoch 615: val_loss improved from 0.03529 to 0.03525, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0320 - val_loss: 0.0352\n",
      "Epoch 616/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0376\n",
      "Epoch 616: val_loss improved from 0.03525 to 0.03521, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0376 - val_loss: 0.0352\n",
      "Epoch 617/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0344\n",
      "Epoch 617: val_loss improved from 0.03521 to 0.03517, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0344 - val_loss: 0.0352\n",
      "Epoch 618/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0335\n",
      "Epoch 618: val_loss improved from 0.03517 to 0.03514, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0335 - val_loss: 0.0351\n",
      "Epoch 619/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0319\n",
      "Epoch 619: val_loss improved from 0.03514 to 0.03510, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0319 - val_loss: 0.0351\n",
      "Epoch 620/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0311\n",
      "Epoch 620: val_loss improved from 0.03510 to 0.03506, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0311 - val_loss: 0.0351\n",
      "Epoch 621/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0300\n",
      "Epoch 621: val_loss improved from 0.03506 to 0.03503, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0300 - val_loss: 0.0350\n",
      "Epoch 622/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0302\n",
      "Epoch 622: val_loss improved from 0.03503 to 0.03499, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0302 - val_loss: 0.0350\n",
      "Epoch 623/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0369\n",
      "Epoch 623: val_loss improved from 0.03499 to 0.03495, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0369 - val_loss: 0.0349\n",
      "Epoch 624/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0288\n",
      "Epoch 624: val_loss improved from 0.03495 to 0.03491, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0288 - val_loss: 0.0349\n",
      "Epoch 625/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0320\n",
      "Epoch 625: val_loss improved from 0.03491 to 0.03487, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0320 - val_loss: 0.0349\n",
      "Epoch 626/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0303\n",
      "Epoch 626: val_loss improved from 0.03487 to 0.03484, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0303 - val_loss: 0.0348\n",
      "Epoch 627/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0312\n",
      "Epoch 627: val_loss improved from 0.03484 to 0.03480, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0312 - val_loss: 0.0348\n",
      "Epoch 628/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0133\n",
      "Epoch 628: val_loss improved from 0.03480 to 0.03476, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 135ms/step - loss: 0.0290 - val_loss: 0.0348\n",
      "Epoch 629/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0366\n",
      "Epoch 629: val_loss improved from 0.03476 to 0.03472, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0366 - val_loss: 0.0347\n",
      "Epoch 630/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0092\n",
      "Epoch 630: val_loss improved from 0.03472 to 0.03469, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0278 - val_loss: 0.0347\n",
      "Epoch 631/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0155\n",
      "Epoch 631: val_loss improved from 0.03469 to 0.03465, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0292 - val_loss: 0.0347\n",
      "Epoch 632/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0273\n",
      "Epoch 632: val_loss improved from 0.03465 to 0.03462, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0273 - val_loss: 0.0346\n",
      "Epoch 633/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0298\n",
      "Epoch 633: val_loss improved from 0.03462 to 0.03458, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0298 - val_loss: 0.0346\n",
      "Epoch 634/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0329\n",
      "Epoch 634: val_loss improved from 0.03458 to 0.03454, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0329 - val_loss: 0.0345\n",
      "Epoch 635/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0324\n",
      "Epoch 635: val_loss improved from 0.03454 to 0.03450, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0324 - val_loss: 0.0345\n",
      "Epoch 636/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0375\n",
      "Epoch 636: val_loss improved from 0.03450 to 0.03446, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0375 - val_loss: 0.0345\n",
      "Epoch 637/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0165\n",
      "Epoch 637: val_loss improved from 0.03446 to 0.03443, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0329 - val_loss: 0.0344\n",
      "Epoch 638/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0363\n",
      "Epoch 638: val_loss improved from 0.03443 to 0.03439, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0363 - val_loss: 0.0344\n",
      "Epoch 639/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0312\n",
      "Epoch 639: val_loss improved from 0.03439 to 0.03435, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0312 - val_loss: 0.0344\n",
      "Epoch 640/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0316\n",
      "Epoch 640: val_loss improved from 0.03435 to 0.03432, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0316 - val_loss: 0.0343\n",
      "Epoch 641/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0346\n",
      "Epoch 641: val_loss improved from 0.03432 to 0.03428, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0346 - val_loss: 0.0343\n",
      "Epoch 642/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0260\n",
      "Epoch 642: val_loss improved from 0.03428 to 0.03424, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0260 - val_loss: 0.0342\n",
      "Epoch 643/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0160\n",
      "Epoch 643: val_loss improved from 0.03424 to 0.03420, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0321 - val_loss: 0.0342\n",
      "Epoch 644/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0299\n",
      "Epoch 644: val_loss improved from 0.03420 to 0.03416, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0299 - val_loss: 0.0342\n",
      "Epoch 645/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0359\n",
      "Epoch 645: val_loss improved from 0.03416 to 0.03413, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0359 - val_loss: 0.0341\n",
      "Epoch 646/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0098\n",
      "Epoch 646: val_loss improved from 0.03413 to 0.03409, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0328 - val_loss: 0.0341\n",
      "Epoch 647/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0378\n",
      "Epoch 647: val_loss improved from 0.03409 to 0.03405, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0378 - val_loss: 0.0341\n",
      "Epoch 648/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0303\n",
      "Epoch 648: val_loss improved from 0.03405 to 0.03401, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0303 - val_loss: 0.0340\n",
      "Epoch 649/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0093\n",
      "Epoch 649: val_loss improved from 0.03401 to 0.03397, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0259 - val_loss: 0.0340\n",
      "Epoch 650/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0249\n",
      "Epoch 650: val_loss improved from 0.03397 to 0.03394, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0249 - val_loss: 0.0339\n",
      "Epoch 651/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0160\n",
      "Epoch 651: val_loss improved from 0.03394 to 0.03390, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0310 - val_loss: 0.0339\n",
      "Epoch 652/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0321\n",
      "Epoch 652: val_loss improved from 0.03390 to 0.03387, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0321 - val_loss: 0.0339\n",
      "Epoch 653/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0267\n",
      "Epoch 653: val_loss improved from 0.03387 to 0.03383, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0267 - val_loss: 0.0338\n",
      "Epoch 654/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0104\n",
      "Epoch 654: val_loss improved from 0.03383 to 0.03379, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0307 - val_loss: 0.0338\n",
      "Epoch 655/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0325\n",
      "Epoch 655: val_loss improved from 0.03379 to 0.03375, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0325 - val_loss: 0.0338\n",
      "Epoch 656/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0098\n",
      "Epoch 656: val_loss improved from 0.03375 to 0.03372, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0270 - val_loss: 0.0337\n",
      "Epoch 657/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0273\n",
      "Epoch 657: val_loss improved from 0.03372 to 0.03368, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0273 - val_loss: 0.0337\n",
      "Epoch 658/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0328\n",
      "Epoch 658: val_loss improved from 0.03368 to 0.03364, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0328 - val_loss: 0.0336\n",
      "Epoch 659/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0374\n",
      "Epoch 659: val_loss improved from 0.03364 to 0.03361, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0374 - val_loss: 0.0336\n",
      "Epoch 660/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0272\n",
      "Epoch 660: val_loss improved from 0.03361 to 0.03358, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0272 - val_loss: 0.0336\n",
      "Epoch 661/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0290\n",
      "Epoch 661: val_loss improved from 0.03358 to 0.03354, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0290 - val_loss: 0.0335\n",
      "Epoch 662/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0102\n",
      "Epoch 662: val_loss improved from 0.03354 to 0.03351, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0269 - val_loss: 0.0335\n",
      "Epoch 663/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0265\n",
      "Epoch 663: val_loss improved from 0.03351 to 0.03347, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0265 - val_loss: 0.0335\n",
      "Epoch 664/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0235\n",
      "Epoch 664: val_loss improved from 0.03347 to 0.03344, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0235 - val_loss: 0.0334\n",
      "Epoch 665/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0341\n",
      "Epoch 665: val_loss improved from 0.03344 to 0.03340, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0341 - val_loss: 0.0334\n",
      "Epoch 666/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0329\n",
      "Epoch 666: val_loss improved from 0.03340 to 0.03337, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0329 - val_loss: 0.0334\n",
      "Epoch 667/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0307\n",
      "Epoch 667: val_loss improved from 0.03337 to 0.03334, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0307 - val_loss: 0.0333\n",
      "Epoch 668/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 668: val_loss improved from 0.03334 to 0.03330, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0237 - val_loss: 0.0333\n",
      "Epoch 669/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0107\n",
      "Epoch 669: val_loss improved from 0.03330 to 0.03327, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0329 - val_loss: 0.0333\n",
      "Epoch 670/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 670: val_loss improved from 0.03327 to 0.03323, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0297 - val_loss: 0.0332\n",
      "Epoch 671/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0089\n",
      "Epoch 671: val_loss improved from 0.03323 to 0.03320, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0317 - val_loss: 0.0332\n",
      "Epoch 672/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0104\n",
      "Epoch 672: val_loss improved from 0.03320 to 0.03317, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0340 - val_loss: 0.0332\n",
      "Epoch 673/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 673: val_loss improved from 0.03317 to 0.03314, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0320 - val_loss: 0.0331\n",
      "Epoch 674/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0314\n",
      "Epoch 674: val_loss improved from 0.03314 to 0.03310, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0314 - val_loss: 0.0331\n",
      "Epoch 675/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0334\n",
      "Epoch 675: val_loss improved from 0.03310 to 0.03307, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0334 - val_loss: 0.0331\n",
      "Epoch 676/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0296\n",
      "Epoch 676: val_loss improved from 0.03307 to 0.03303, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0296 - val_loss: 0.0330\n",
      "Epoch 677/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0324\n",
      "Epoch 677: val_loss improved from 0.03303 to 0.03300, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0324 - val_loss: 0.0330\n",
      "Epoch 678/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0107\n",
      "Epoch 678: val_loss improved from 0.03300 to 0.03297, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0238 - val_loss: 0.0330\n",
      "Epoch 679/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0309\n",
      "Epoch 679: val_loss improved from 0.03297 to 0.03293, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0309 - val_loss: 0.0329\n",
      "Epoch 680/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0321\n",
      "Epoch 680: val_loss improved from 0.03293 to 0.03290, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0321 - val_loss: 0.0329\n",
      "Epoch 681/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0224\n",
      "Epoch 681: val_loss improved from 0.03290 to 0.03287, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0224 - val_loss: 0.0329\n",
      "Epoch 682/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0308\n",
      "Epoch 682: val_loss improved from 0.03287 to 0.03284, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0308 - val_loss: 0.0328\n",
      "Epoch 683/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0313\n",
      "Epoch 683: val_loss improved from 0.03284 to 0.03280, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0313 - val_loss: 0.0328\n",
      "Epoch 684/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0366\n",
      "Epoch 684: val_loss improved from 0.03280 to 0.03277, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0366 - val_loss: 0.0328\n",
      "Epoch 685/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0252\n",
      "Epoch 685: val_loss improved from 0.03277 to 0.03274, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0252 - val_loss: 0.0327\n",
      "Epoch 686/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0117\n",
      "Epoch 686: val_loss improved from 0.03274 to 0.03270, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0299 - val_loss: 0.0327\n",
      "Epoch 687/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0315\n",
      "Epoch 687: val_loss improved from 0.03270 to 0.03267, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0315 - val_loss: 0.0327\n",
      "Epoch 688/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0338\n",
      "Epoch 688: val_loss improved from 0.03267 to 0.03264, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0338 - val_loss: 0.0326\n",
      "Epoch 689/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0369\n",
      "Epoch 689: val_loss improved from 0.03264 to 0.03261, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0369 - val_loss: 0.0326\n",
      "Epoch 690/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0257\n",
      "Epoch 690: val_loss improved from 0.03261 to 0.03258, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0257 - val_loss: 0.0326\n",
      "Epoch 691/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0346\n",
      "Epoch 691: val_loss improved from 0.03258 to 0.03255, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0346 - val_loss: 0.0326\n",
      "Epoch 692/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0118\n",
      "Epoch 692: val_loss improved from 0.03255 to 0.03253, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0377 - val_loss: 0.0325\n",
      "Epoch 693/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0307\n",
      "Epoch 693: val_loss improved from 0.03253 to 0.03250, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0307 - val_loss: 0.0325\n",
      "Epoch 694/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0281\n",
      "Epoch 694: val_loss improved from 0.03250 to 0.03247, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0281 - val_loss: 0.0325\n",
      "Epoch 695/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0085\n",
      "Epoch 695: val_loss improved from 0.03247 to 0.03244, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0354 - val_loss: 0.0324\n",
      "Epoch 696/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0375\n",
      "Epoch 696: val_loss improved from 0.03244 to 0.03241, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0375 - val_loss: 0.0324\n",
      "Epoch 697/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0268\n",
      "Epoch 697: val_loss improved from 0.03241 to 0.03238, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0268 - val_loss: 0.0324\n",
      "Epoch 698/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0262\n",
      "Epoch 698: val_loss improved from 0.03238 to 0.03235, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0262 - val_loss: 0.0324\n",
      "Epoch 699/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 699: val_loss improved from 0.03235 to 0.03232, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0237 - val_loss: 0.0323\n",
      "Epoch 700/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0262\n",
      "Epoch 700: val_loss improved from 0.03232 to 0.03229, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0262 - val_loss: 0.0323\n",
      "Epoch 701/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0364\n",
      "Epoch 701: val_loss improved from 0.03229 to 0.03226, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0364 - val_loss: 0.0323\n",
      "Epoch 702/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0353\n",
      "Epoch 702: val_loss improved from 0.03226 to 0.03224, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0353 - val_loss: 0.0322\n",
      "Epoch 703/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 703: val_loss improved from 0.03224 to 0.03221, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0315 - val_loss: 0.0322\n",
      "Epoch 704/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0251\n",
      "Epoch 704: val_loss improved from 0.03221 to 0.03218, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0251 - val_loss: 0.0322\n",
      "Epoch 705/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0331\n",
      "Epoch 705: val_loss improved from 0.03218 to 0.03215, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0331 - val_loss: 0.0322\n",
      "Epoch 706/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 706: val_loss improved from 0.03215 to 0.03213, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0378 - val_loss: 0.0321\n",
      "Epoch 707/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0309\n",
      "Epoch 707: val_loss improved from 0.03213 to 0.03210, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0309 - val_loss: 0.0321\n",
      "Epoch 708/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 708: val_loss improved from 0.03210 to 0.03207, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0382 - val_loss: 0.0321\n",
      "Epoch 709/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0249\n",
      "Epoch 709: val_loss improved from 0.03207 to 0.03204, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0249 - val_loss: 0.0320\n",
      "Epoch 710/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0244\n",
      "Epoch 710: val_loss improved from 0.03204 to 0.03201, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0244 - val_loss: 0.0320\n",
      "Epoch 711/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 711: val_loss improved from 0.03201 to 0.03198, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0273 - val_loss: 0.0320\n",
      "Epoch 712/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 712: val_loss improved from 0.03198 to 0.03195, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0293 - val_loss: 0.0320\n",
      "Epoch 713/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0248\n",
      "Epoch 713: val_loss improved from 0.03195 to 0.03192, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0248 - val_loss: 0.0319\n",
      "Epoch 714/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0303\n",
      "Epoch 714: val_loss improved from 0.03192 to 0.03190, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0303 - val_loss: 0.0319\n",
      "Epoch 715/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0085\n",
      "Epoch 715: val_loss improved from 0.03190 to 0.03187, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0243 - val_loss: 0.0319\n",
      "Epoch 716/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0380\n",
      "Epoch 716: val_loss improved from 0.03187 to 0.03184, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0380 - val_loss: 0.0318\n",
      "Epoch 717/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0377\n",
      "Epoch 717: val_loss improved from 0.03184 to 0.03181, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 117ms/step - loss: 0.0377 - val_loss: 0.0318\n",
      "Epoch 718/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0224\n",
      "Epoch 718: val_loss improved from 0.03181 to 0.03178, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0224 - val_loss: 0.0318\n",
      "Epoch 719/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0118\n",
      "Epoch 719: val_loss improved from 0.03178 to 0.03175, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0315 - val_loss: 0.0318\n",
      "Epoch 720/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0252\n",
      "Epoch 720: val_loss improved from 0.03175 to 0.03172, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0252 - val_loss: 0.0317\n",
      "Epoch 721/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0258\n",
      "Epoch 721: val_loss improved from 0.03172 to 0.03169, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0258 - val_loss: 0.0317\n",
      "Epoch 722/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0271\n",
      "Epoch 722: val_loss improved from 0.03169 to 0.03167, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0271 - val_loss: 0.0317\n",
      "Epoch 723/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0389\n",
      "Epoch 723: val_loss improved from 0.03167 to 0.03164, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0389 - val_loss: 0.0316\n",
      "Epoch 724/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 724: val_loss improved from 0.03164 to 0.03161, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0237 - val_loss: 0.0316\n",
      "Epoch 725/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0093\n",
      "Epoch 725: val_loss improved from 0.03161 to 0.03158, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0412 - val_loss: 0.0316\n",
      "Epoch 726/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 726: val_loss improved from 0.03158 to 0.03155, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0238 - val_loss: 0.0316\n",
      "Epoch 727/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0388\n",
      "Epoch 727: val_loss improved from 0.03155 to 0.03152, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0388 - val_loss: 0.0315\n",
      "Epoch 728/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0259\n",
      "Epoch 728: val_loss improved from 0.03152 to 0.03150, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0259 - val_loss: 0.0315\n",
      "Epoch 729/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0082\n",
      "Epoch 729: val_loss improved from 0.03150 to 0.03147, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0325 - val_loss: 0.0315\n",
      "Epoch 730/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0298\n",
      "Epoch 730: val_loss improved from 0.03147 to 0.03144, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0298 - val_loss: 0.0314\n",
      "Epoch 731/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0235\n",
      "Epoch 731: val_loss improved from 0.03144 to 0.03141, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0235 - val_loss: 0.0314\n",
      "Epoch 732/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0285\n",
      "Epoch 732: val_loss improved from 0.03141 to 0.03138, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0285 - val_loss: 0.0314\n",
      "Epoch 733/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0109\n",
      "Epoch 733: val_loss improved from 0.03138 to 0.03136, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0318 - val_loss: 0.0314\n",
      "Epoch 734/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0363\n",
      "Epoch 734: val_loss improved from 0.03136 to 0.03133, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0363 - val_loss: 0.0313\n",
      "Epoch 735/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 735: val_loss improved from 0.03133 to 0.03130, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0274 - val_loss: 0.0313\n",
      "Epoch 736/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0095\n",
      "Epoch 736: val_loss improved from 0.03130 to 0.03127, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0236 - val_loss: 0.0313\n",
      "Epoch 737/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 737: val_loss improved from 0.03127 to 0.03124, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0258 - val_loss: 0.0312\n",
      "Epoch 738/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0248\n",
      "Epoch 738: val_loss improved from 0.03124 to 0.03122, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0248 - val_loss: 0.0312\n",
      "Epoch 739/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0093\n",
      "Epoch 739: val_loss improved from 0.03122 to 0.03119, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0286 - val_loss: 0.0312\n",
      "Epoch 740/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0109\n",
      "Epoch 740: val_loss improved from 0.03119 to 0.03116, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0281 - val_loss: 0.0312\n",
      "Epoch 741/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0268\n",
      "Epoch 741: val_loss improved from 0.03116 to 0.03113, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0268 - val_loss: 0.0311\n",
      "Epoch 742/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0322\n",
      "Epoch 742: val_loss improved from 0.03113 to 0.03111, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 112ms/step - loss: 0.0322 - val_loss: 0.0311\n",
      "Epoch 743/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0092\n",
      "Epoch 743: val_loss improved from 0.03111 to 0.03108, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0239 - val_loss: 0.0311\n",
      "Epoch 744/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0297\n",
      "Epoch 744: val_loss improved from 0.03108 to 0.03105, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0297 - val_loss: 0.0311\n",
      "Epoch 745/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0295\n",
      "Epoch 745: val_loss improved from 0.03105 to 0.03103, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0295 - val_loss: 0.0310\n",
      "Epoch 746/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0246\n",
      "Epoch 746: val_loss improved from 0.03103 to 0.03100, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0246 - val_loss: 0.0310\n",
      "Epoch 747/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0338\n",
      "Epoch 747: val_loss improved from 0.03100 to 0.03098, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0338 - val_loss: 0.0310\n",
      "Epoch 748/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0295\n",
      "Epoch 748: val_loss improved from 0.03098 to 0.03095, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0295 - val_loss: 0.0310\n",
      "Epoch 749/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0288\n",
      "Epoch 749: val_loss improved from 0.03095 to 0.03092, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0288 - val_loss: 0.0309\n",
      "Epoch 750/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0296\n",
      "Epoch 750: val_loss improved from 0.03092 to 0.03090, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0296 - val_loss: 0.0309\n",
      "Epoch 751/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 751: val_loss improved from 0.03090 to 0.03087, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0237 - val_loss: 0.0309\n",
      "Epoch 752/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 752: val_loss improved from 0.03087 to 0.03085, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0278 - val_loss: 0.0308\n",
      "Epoch 753/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0342\n",
      "Epoch 753: val_loss improved from 0.03085 to 0.03082, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0342 - val_loss: 0.0308\n",
      "Epoch 754/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0278\n",
      "Epoch 754: val_loss improved from 0.03082 to 0.03079, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 114ms/step - loss: 0.0278 - val_loss: 0.0308\n",
      "Epoch 755/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0104\n",
      "Epoch 755: val_loss improved from 0.03079 to 0.03077, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0188 - val_loss: 0.0308\n",
      "Epoch 756/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0151\n",
      "Epoch 756: val_loss improved from 0.03077 to 0.03074, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0282 - val_loss: 0.0307\n",
      "Epoch 757/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0079\n",
      "Epoch 757: val_loss improved from 0.03074 to 0.03072, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0259 - val_loss: 0.0307\n",
      "Epoch 758/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0224\n",
      "Epoch 758: val_loss improved from 0.03072 to 0.03069, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0224 - val_loss: 0.0307\n",
      "Epoch 759/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0303\n",
      "Epoch 759: val_loss improved from 0.03069 to 0.03066, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0303 - val_loss: 0.0307\n",
      "Epoch 760/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0184\n",
      "Epoch 760: val_loss improved from 0.03066 to 0.03064, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0184 - val_loss: 0.0306\n",
      "Epoch 761/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0286\n",
      "Epoch 761: val_loss improved from 0.03064 to 0.03062, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0286 - val_loss: 0.0306\n",
      "Epoch 762/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0085\n",
      "Epoch 762: val_loss improved from 0.03062 to 0.03059, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0248 - val_loss: 0.0306\n",
      "Epoch 763/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0096\n",
      "Epoch 763: val_loss improved from 0.03059 to 0.03056, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0237 - val_loss: 0.0306\n",
      "Epoch 764/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0227\n",
      "Epoch 764: val_loss improved from 0.03056 to 0.03054, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0227 - val_loss: 0.0305\n",
      "Epoch 765/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0105\n",
      "Epoch 765: val_loss improved from 0.03054 to 0.03051, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0281 - val_loss: 0.0305\n",
      "Epoch 766/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0110\n",
      "Epoch 766: val_loss improved from 0.03051 to 0.03049, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0246 - val_loss: 0.0305\n",
      "Epoch 767/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0291\n",
      "Epoch 767: val_loss improved from 0.03049 to 0.03046, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0291 - val_loss: 0.0305\n",
      "Epoch 768/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0151\n",
      "Epoch 768: val_loss improved from 0.03046 to 0.03044, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0393 - val_loss: 0.0304\n",
      "Epoch 769/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0285\n",
      "Epoch 769: val_loss improved from 0.03044 to 0.03041, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0285 - val_loss: 0.0304\n",
      "Epoch 770/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0095\n",
      "Epoch 770: val_loss improved from 0.03041 to 0.03039, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0266 - val_loss: 0.0304\n",
      "Epoch 771/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0098\n",
      "Epoch 771: val_loss improved from 0.03039 to 0.03036, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 65ms/step - loss: 0.0291 - val_loss: 0.0304\n",
      "Epoch 772/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0099\n",
      "Epoch 772: val_loss improved from 0.03036 to 0.03033, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0257 - val_loss: 0.0303\n",
      "Epoch 773/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0088\n",
      "Epoch 773: val_loss improved from 0.03033 to 0.03031, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0266 - val_loss: 0.0303\n",
      "Epoch 774/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0088\n",
      "Epoch 774: val_loss improved from 0.03031 to 0.03028, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0288 - val_loss: 0.0303\n",
      "Epoch 775/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0105\n",
      "Epoch 775: val_loss improved from 0.03028 to 0.03026, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0259 - val_loss: 0.0303\n",
      "Epoch 776/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0116\n",
      "Epoch 776: val_loss improved from 0.03026 to 0.03023, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0285 - val_loss: 0.0302\n",
      "Epoch 777/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0113\n",
      "Epoch 777: val_loss improved from 0.03023 to 0.03021, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0255 - val_loss: 0.0302\n",
      "Epoch 778/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0102\n",
      "Epoch 778: val_loss improved from 0.03021 to 0.03018, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 67ms/step - loss: 0.0280 - val_loss: 0.0302\n",
      "Epoch 779/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0107\n",
      "Epoch 779: val_loss improved from 0.03018 to 0.03015, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0245 - val_loss: 0.0302\n",
      "Epoch 780/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0094\n",
      "Epoch 780: val_loss improved from 0.03015 to 0.03013, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0287 - val_loss: 0.0301\n",
      "Epoch 781/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0102\n",
      "Epoch 781: val_loss improved from 0.03013 to 0.03010, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0257 - val_loss: 0.0301\n",
      "Epoch 782/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 782: val_loss improved from 0.03010 to 0.03008, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0220 - val_loss: 0.0301\n",
      "Epoch 783/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0088\n",
      "Epoch 783: val_loss improved from 0.03008 to 0.03005, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0257 - val_loss: 0.0301\n",
      "Epoch 784/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 784: val_loss improved from 0.03005 to 0.03003, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0274 - val_loss: 0.0300\n",
      "Epoch 785/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0121\n",
      "Epoch 785: val_loss improved from 0.03003 to 0.03000, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0280 - val_loss: 0.0300\n",
      "Epoch 786/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0365\n",
      "Epoch 786: val_loss improved from 0.03000 to 0.02997, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 108ms/step - loss: 0.0365 - val_loss: 0.0300\n",
      "Epoch 787/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0083\n",
      "Epoch 787: val_loss improved from 0.02997 to 0.02995, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0362 - val_loss: 0.0299\n",
      "Epoch 788/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0112\n",
      "Epoch 788: val_loss improved from 0.02995 to 0.02992, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0401 - val_loss: 0.0299\n",
      "Epoch 789/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0143\n",
      "Epoch 789: val_loss improved from 0.02992 to 0.02989, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0337 - val_loss: 0.0299\n",
      "Epoch 790/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0295\n",
      "Epoch 790: val_loss improved from 0.02989 to 0.02986, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0295 - val_loss: 0.0299\n",
      "Epoch 791/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0089\n",
      "Epoch 791: val_loss improved from 0.02986 to 0.02984, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0235 - val_loss: 0.0298\n",
      "Epoch 792/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0097\n",
      "Epoch 792: val_loss improved from 0.02984 to 0.02981, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0287 - val_loss: 0.0298\n",
      "Epoch 793/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0096\n",
      "Epoch 793: val_loss improved from 0.02981 to 0.02979, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0247 - val_loss: 0.0298\n",
      "Epoch 794/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0241\n",
      "Epoch 794: val_loss improved from 0.02979 to 0.02976, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0241 - val_loss: 0.0298\n",
      "Epoch 795/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0093\n",
      "Epoch 795: val_loss improved from 0.02976 to 0.02973, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0297 - val_loss: 0.0297\n",
      "Epoch 796/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0240\n",
      "Epoch 796: val_loss improved from 0.02973 to 0.02971, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 0.0240 - val_loss: 0.0297\n",
      "Epoch 797/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0283\n",
      "Epoch 797: val_loss improved from 0.02971 to 0.02968, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 127ms/step - loss: 0.0283 - val_loss: 0.0297\n",
      "Epoch 798/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0234\n",
      "Epoch 798: val_loss improved from 0.02968 to 0.02965, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 129ms/step - loss: 0.0234 - val_loss: 0.0297\n",
      "Epoch 799/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0270\n",
      "Epoch 799: val_loss improved from 0.02965 to 0.02963, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 156ms/step - loss: 0.0270 - val_loss: 0.0296\n",
      "Epoch 800/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0329\n",
      "Epoch 800: val_loss improved from 0.02963 to 0.02960, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 172ms/step - loss: 0.0329 - val_loss: 0.0296\n",
      "Epoch 801/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0271\n",
      "Epoch 801: val_loss improved from 0.02960 to 0.02958, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0271 - val_loss: 0.0296\n",
      "Epoch 802/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0191\n",
      "Epoch 802: val_loss improved from 0.02958 to 0.02955, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0191 - val_loss: 0.0296\n",
      "Epoch 803/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0308\n",
      "Epoch 803: val_loss improved from 0.02955 to 0.02953, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0308 - val_loss: 0.0295\n",
      "Epoch 804/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0229\n",
      "Epoch 804: val_loss improved from 0.02953 to 0.02950, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0229 - val_loss: 0.0295\n",
      "Epoch 805/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0307\n",
      "Epoch 805: val_loss improved from 0.02950 to 0.02948, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0307 - val_loss: 0.0295\n",
      "Epoch 806/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0312\n",
      "Epoch 806: val_loss improved from 0.02948 to 0.02945, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 161ms/step - loss: 0.0312 - val_loss: 0.0294\n",
      "Epoch 807/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0276\n",
      "Epoch 807: val_loss improved from 0.02945 to 0.02942, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 144ms/step - loss: 0.0276 - val_loss: 0.0294\n",
      "Epoch 808/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0277\n",
      "Epoch 808: val_loss improved from 0.02942 to 0.02940, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0277 - val_loss: 0.0294\n",
      "Epoch 809/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0342\n",
      "Epoch 809: val_loss improved from 0.02940 to 0.02937, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0342 - val_loss: 0.0294\n",
      "Epoch 810/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0254\n",
      "Epoch 810: val_loss improved from 0.02937 to 0.02934, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0254 - val_loss: 0.0293\n",
      "Epoch 811/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0241\n",
      "Epoch 811: val_loss improved from 0.02934 to 0.02932, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0241 - val_loss: 0.0293\n",
      "Epoch 812/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0241\n",
      "Epoch 812: val_loss improved from 0.02932 to 0.02929, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 119ms/step - loss: 0.0241 - val_loss: 0.0293\n",
      "Epoch 813/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0254\n",
      "Epoch 813: val_loss improved from 0.02929 to 0.02927, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0254 - val_loss: 0.0293\n",
      "Epoch 814/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0276\n",
      "Epoch 814: val_loss improved from 0.02927 to 0.02924, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 166ms/step - loss: 0.0276 - val_loss: 0.0292\n",
      "Epoch 815/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0254\n",
      "Epoch 815: val_loss improved from 0.02924 to 0.02922, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0254 - val_loss: 0.0292\n",
      "Epoch 816/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0283\n",
      "Epoch 816: val_loss improved from 0.02922 to 0.02919, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 124ms/step - loss: 0.0283 - val_loss: 0.0292\n",
      "Epoch 817/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0254\n",
      "Epoch 817: val_loss improved from 0.02919 to 0.02917, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0254 - val_loss: 0.0292\n",
      "Epoch 818/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0302\n",
      "Epoch 818: val_loss improved from 0.02917 to 0.02914, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 139ms/step - loss: 0.0302 - val_loss: 0.0291\n",
      "Epoch 819/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0249\n",
      "Epoch 819: val_loss improved from 0.02914 to 0.02912, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 0.0249 - val_loss: 0.0291\n",
      "Epoch 820/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0211\n",
      "Epoch 820: val_loss improved from 0.02912 to 0.02909, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0211 - val_loss: 0.0291\n",
      "Epoch 821/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0247\n",
      "Epoch 821: val_loss improved from 0.02909 to 0.02907, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0247 - val_loss: 0.0291\n",
      "Epoch 822/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0263\n",
      "Epoch 822: val_loss improved from 0.02907 to 0.02905, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 178ms/step - loss: 0.0263 - val_loss: 0.0290\n",
      "Epoch 823/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0249\n",
      "Epoch 823: val_loss improved from 0.02905 to 0.02902, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 0.0249 - val_loss: 0.0290\n",
      "Epoch 824/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0214\n",
      "Epoch 824: val_loss improved from 0.02902 to 0.02900, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 120ms/step - loss: 0.0214 - val_loss: 0.0290\n",
      "Epoch 825/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0297\n",
      "Epoch 825: val_loss improved from 0.02900 to 0.02898, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 123ms/step - loss: 0.0297 - val_loss: 0.0290\n",
      "Epoch 826/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0097\n",
      "Epoch 826: val_loss improved from 0.02898 to 0.02896, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0219 - val_loss: 0.0290\n",
      "Epoch 827/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0262\n",
      "Epoch 827: val_loss improved from 0.02896 to 0.02893, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0262 - val_loss: 0.0289\n",
      "Epoch 828/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0252\n",
      "Epoch 828: val_loss improved from 0.02893 to 0.02891, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0252 - val_loss: 0.0289\n",
      "Epoch 829/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0273\n",
      "Epoch 829: val_loss improved from 0.02891 to 0.02889, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 109ms/step - loss: 0.0273 - val_loss: 0.0289\n",
      "Epoch 830/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 830: val_loss improved from 0.02889 to 0.02886, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0269 - val_loss: 0.0289\n",
      "Epoch 831/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0277\n",
      "Epoch 831: val_loss improved from 0.02886 to 0.02884, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 115ms/step - loss: 0.0277 - val_loss: 0.0288\n",
      "Epoch 832/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0241\n",
      "Epoch 832: val_loss improved from 0.02884 to 0.02882, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0241 - val_loss: 0.0288\n",
      "Epoch 833/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0202\n",
      "Epoch 833: val_loss improved from 0.02882 to 0.02879, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 121ms/step - loss: 0.0202 - val_loss: 0.0288\n",
      "Epoch 834/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0315\n",
      "Epoch 834: val_loss improved from 0.02879 to 0.02877, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0315 - val_loss: 0.0288\n",
      "Epoch 835/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0254\n",
      "Epoch 835: val_loss improved from 0.02877 to 0.02875, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0254 - val_loss: 0.0287\n",
      "Epoch 836/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0269\n",
      "Epoch 836: val_loss improved from 0.02875 to 0.02873, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0269 - val_loss: 0.0287\n",
      "Epoch 837/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0215\n",
      "Epoch 837: val_loss improved from 0.02873 to 0.02870, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0215 - val_loss: 0.0287\n",
      "Epoch 838/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0238\n",
      "Epoch 838: val_loss improved from 0.02870 to 0.02868, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0238 - val_loss: 0.0287\n",
      "Epoch 839/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0292\n",
      "Epoch 839: val_loss improved from 0.02868 to 0.02866, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0292 - val_loss: 0.0287\n",
      "Epoch 840/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0255\n",
      "Epoch 840: val_loss improved from 0.02866 to 0.02864, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0255 - val_loss: 0.0286\n",
      "Epoch 841/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 841: val_loss improved from 0.02864 to 0.02862, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 0.0237 - val_loss: 0.0286\n",
      "Epoch 842/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0225\n",
      "Epoch 842: val_loss improved from 0.02862 to 0.02860, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 118ms/step - loss: 0.0225 - val_loss: 0.0286\n",
      "Epoch 843/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0275\n",
      "Epoch 843: val_loss improved from 0.02860 to 0.02858, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 136ms/step - loss: 0.0275 - val_loss: 0.0286\n",
      "Epoch 844/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0153\n",
      "Epoch 844: val_loss improved from 0.02858 to 0.02856, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 0.0297 - val_loss: 0.0286\n",
      "Epoch 845/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0151\n",
      "Epoch 845: val_loss improved from 0.02856 to 0.02854, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 195ms/step - loss: 0.0200 - val_loss: 0.0285\n",
      "Epoch 846/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0252\n",
      "Epoch 846: val_loss improved from 0.02854 to 0.02852, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 0.0252 - val_loss: 0.0285\n",
      "Epoch 847/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0283\n",
      "Epoch 847: val_loss improved from 0.02852 to 0.02850, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 131ms/step - loss: 0.0283 - val_loss: 0.0285\n",
      "Epoch 848/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0240\n",
      "Epoch 848: val_loss improved from 0.02850 to 0.02848, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 0.0240 - val_loss: 0.0285\n",
      "Epoch 849/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0221\n",
      "Epoch 849: val_loss improved from 0.02848 to 0.02846, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 0.0221 - val_loss: 0.0285\n",
      "Epoch 850/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0174\n",
      "Epoch 850: val_loss improved from 0.02846 to 0.02844, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 0.0174 - val_loss: 0.0284\n",
      "Epoch 851/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0246\n",
      "Epoch 851: val_loss improved from 0.02844 to 0.02842, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 219ms/step - loss: 0.0246 - val_loss: 0.0284\n",
      "Epoch 852/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0275\n",
      "Epoch 852: val_loss improved from 0.02842 to 0.02840, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 179ms/step - loss: 0.0275 - val_loss: 0.0284\n",
      "Epoch 853/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0097\n",
      "Epoch 853: val_loss improved from 0.02840 to 0.02838, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 116ms/step - loss: 0.0245 - val_loss: 0.0284\n",
      "Epoch 854/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0312\n",
      "Epoch 854: val_loss improved from 0.02838 to 0.02837, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0312 - val_loss: 0.0284\n",
      "Epoch 855/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0223\n",
      "Epoch 855: val_loss improved from 0.02837 to 0.02835, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0223 - val_loss: 0.0283\n",
      "Epoch 856/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 856: val_loss improved from 0.02835 to 0.02833, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0288 - val_loss: 0.0283\n",
      "Epoch 857/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0300\n",
      "Epoch 857: val_loss improved from 0.02833 to 0.02831, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0300 - val_loss: 0.0283\n",
      "Epoch 858/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0195\n",
      "Epoch 858: val_loss improved from 0.02831 to 0.02829, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0195 - val_loss: 0.0283\n",
      "Epoch 859/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0094\n",
      "Epoch 859: val_loss improved from 0.02829 to 0.02827, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0318 - val_loss: 0.0283\n",
      "Epoch 860/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0236\n",
      "Epoch 860: val_loss improved from 0.02827 to 0.02825, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0236 - val_loss: 0.0283\n",
      "Epoch 861/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0331\n",
      "Epoch 861: val_loss improved from 0.02825 to 0.02824, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 0.0331 - val_loss: 0.0282\n",
      "Epoch 862/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0082\n",
      "Epoch 862: val_loss improved from 0.02824 to 0.02822, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0210 - val_loss: 0.0282\n",
      "Epoch 863/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0272\n",
      "Epoch 863: val_loss improved from 0.02822 to 0.02820, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0272 - val_loss: 0.0282\n",
      "Epoch 864/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0211\n",
      "Epoch 864: val_loss improved from 0.02820 to 0.02818, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0211 - val_loss: 0.0282\n",
      "Epoch 865/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0244\n",
      "Epoch 865: val_loss improved from 0.02818 to 0.02816, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0244 - val_loss: 0.0282\n",
      "Epoch 866/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0088\n",
      "Epoch 866: val_loss improved from 0.02816 to 0.02814, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0232 - val_loss: 0.0281\n",
      "Epoch 867/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0240\n",
      "Epoch 867: val_loss improved from 0.02814 to 0.02813, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0240 - val_loss: 0.0281\n",
      "Epoch 868/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0299\n",
      "Epoch 868: val_loss improved from 0.02813 to 0.02811, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 110ms/step - loss: 0.0299 - val_loss: 0.0281\n",
      "Epoch 869/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0100\n",
      "Epoch 869: val_loss improved from 0.02811 to 0.02809, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0207 - val_loss: 0.0281\n",
      "Epoch 870/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0302\n",
      "Epoch 870: val_loss improved from 0.02809 to 0.02807, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 0.0302 - val_loss: 0.0281\n",
      "Epoch 871/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 871: val_loss improved from 0.02807 to 0.02805, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0211 - val_loss: 0.0281\n",
      "Epoch 872/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0231\n",
      "Epoch 872: val_loss improved from 0.02805 to 0.02804, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0231 - val_loss: 0.0280\n",
      "Epoch 873/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0075\n",
      "Epoch 873: val_loss improved from 0.02804 to 0.02802, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0249 - val_loss: 0.0280\n",
      "Epoch 874/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0228\n",
      "Epoch 874: val_loss improved from 0.02802 to 0.02800, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 0.0228 - val_loss: 0.0280\n",
      "Epoch 875/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0089\n",
      "Epoch 875: val_loss improved from 0.02800 to 0.02798, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0193 - val_loss: 0.0280\n",
      "Epoch 876/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0244\n",
      "Epoch 876: val_loss improved from 0.02798 to 0.02796, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0244 - val_loss: 0.0280\n",
      "Epoch 877/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0079\n",
      "Epoch 877: val_loss improved from 0.02796 to 0.02794, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 0.0204 - val_loss: 0.0279\n",
      "Epoch 878/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0085\n",
      "Epoch 878: val_loss improved from 0.02794 to 0.02793, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0351 - val_loss: 0.0279\n",
      "Epoch 879/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0261\n",
      "Epoch 879: val_loss improved from 0.02793 to 0.02791, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0261 - val_loss: 0.0279\n",
      "Epoch 880/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0096\n",
      "Epoch 880: val_loss improved from 0.02791 to 0.02789, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 107ms/step - loss: 0.0230 - val_loss: 0.0279\n",
      "Epoch 881/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0232\n",
      "Epoch 881: val_loss improved from 0.02789 to 0.02787, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 0.0232 - val_loss: 0.0279\n",
      "Epoch 882/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0095\n",
      "Epoch 882: val_loss improved from 0.02787 to 0.02785, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0202 - val_loss: 0.0279\n",
      "Epoch 883/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0099\n",
      "Epoch 883: val_loss improved from 0.02785 to 0.02783, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0355 - val_loss: 0.0278\n",
      "Epoch 884/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0087\n",
      "Epoch 884: val_loss improved from 0.02783 to 0.02781, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0198 - val_loss: 0.0278\n",
      "Epoch 885/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0096\n",
      "Epoch 885: val_loss improved from 0.02781 to 0.02779, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0235 - val_loss: 0.0278\n",
      "Epoch 886/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0215\n",
      "Epoch 886: val_loss improved from 0.02779 to 0.02778, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0215 - val_loss: 0.0278\n",
      "Epoch 887/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0094\n",
      "Epoch 887: val_loss improved from 0.02778 to 0.02776, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0173 - val_loss: 0.0278\n",
      "Epoch 888/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0312\n",
      "Epoch 888: val_loss improved from 0.02776 to 0.02774, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0312 - val_loss: 0.0277\n",
      "Epoch 889/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0245\n",
      "Epoch 889: val_loss improved from 0.02774 to 0.02773, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0245 - val_loss: 0.0277\n",
      "Epoch 890/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0087\n",
      "Epoch 890: val_loss improved from 0.02773 to 0.02771, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0250 - val_loss: 0.0277\n",
      "Epoch 891/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0089\n",
      "Epoch 891: val_loss improved from 0.02771 to 0.02769, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 113ms/step - loss: 0.0208 - val_loss: 0.0277\n",
      "Epoch 892/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0088\n",
      "Epoch 892: val_loss improved from 0.02769 to 0.02768, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0200 - val_loss: 0.0277\n",
      "Epoch 893/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0233\n",
      "Epoch 893: val_loss improved from 0.02768 to 0.02766, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0233 - val_loss: 0.0277\n",
      "Epoch 894/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 894: val_loss improved from 0.02766 to 0.02764, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0235 - val_loss: 0.0276\n",
      "Epoch 895/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0251\n",
      "Epoch 895: val_loss improved from 0.02764 to 0.02762, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0251 - val_loss: 0.0276\n",
      "Epoch 896/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0254\n",
      "Epoch 896: val_loss improved from 0.02762 to 0.02760, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0254 - val_loss: 0.0276\n",
      "Epoch 897/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0182\n",
      "Epoch 897: val_loss improved from 0.02760 to 0.02758, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0182 - val_loss: 0.0276\n",
      "Epoch 898/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0080\n",
      "Epoch 898: val_loss improved from 0.02758 to 0.02756, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0221 - val_loss: 0.0276\n",
      "Epoch 899/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 899: val_loss improved from 0.02756 to 0.02755, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0226 - val_loss: 0.0275\n",
      "Epoch 900/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0215\n",
      "Epoch 900: val_loss improved from 0.02755 to 0.02753, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 125ms/step - loss: 0.0215 - val_loss: 0.0275\n",
      "Epoch 901/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0092\n",
      "Epoch 901: val_loss improved from 0.02753 to 0.02751, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0213 - val_loss: 0.0275\n",
      "Epoch 902/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0083\n",
      "Epoch 902: val_loss improved from 0.02751 to 0.02749, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0275 - val_loss: 0.0275\n",
      "Epoch 903/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0227\n",
      "Epoch 903: val_loss improved from 0.02749 to 0.02747, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0227 - val_loss: 0.0275\n",
      "Epoch 904/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0272\n",
      "Epoch 904: val_loss improved from 0.02747 to 0.02746, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0272 - val_loss: 0.0275\n",
      "Epoch 905/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0216\n",
      "Epoch 905: val_loss improved from 0.02746 to 0.02744, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0216 - val_loss: 0.0274\n",
      "Epoch 906/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0180\n",
      "Epoch 906: val_loss improved from 0.02744 to 0.02742, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0180 - val_loss: 0.0274\n",
      "Epoch 907/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0094\n",
      "Epoch 907: val_loss improved from 0.02742 to 0.02740, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0219 - val_loss: 0.0274\n",
      "Epoch 908/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0090\n",
      "Epoch 908: val_loss improved from 0.02740 to 0.02738, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0235 - val_loss: 0.0274\n",
      "Epoch 909/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0228\n",
      "Epoch 909: val_loss improved from 0.02738 to 0.02736, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0228 - val_loss: 0.0274\n",
      "Epoch 910/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0089\n",
      "Epoch 910: val_loss improved from 0.02736 to 0.02734, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0238 - val_loss: 0.0273\n",
      "Epoch 911/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0079\n",
      "Epoch 911: val_loss improved from 0.02734 to 0.02732, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0277 - val_loss: 0.0273\n",
      "Epoch 912/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0225\n",
      "Epoch 912: val_loss improved from 0.02732 to 0.02730, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0225 - val_loss: 0.0273\n",
      "Epoch 913/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0114\n",
      "Epoch 913: val_loss improved from 0.02730 to 0.02729, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0293 - val_loss: 0.0273\n",
      "Epoch 914/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0200\n",
      "Epoch 914: val_loss improved from 0.02729 to 0.02727, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0200 - val_loss: 0.0273\n",
      "Epoch 915/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0095\n",
      "Epoch 915: val_loss improved from 0.02727 to 0.02725, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0222 - val_loss: 0.0272\n",
      "Epoch 916/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0208\n",
      "Epoch 916: val_loss improved from 0.02725 to 0.02723, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0208 - val_loss: 0.0272\n",
      "Epoch 917/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0257\n",
      "Epoch 917: val_loss improved from 0.02723 to 0.02721, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0257 - val_loss: 0.0272\n",
      "Epoch 918/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0098\n",
      "Epoch 918: val_loss improved from 0.02721 to 0.02719, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0233 - val_loss: 0.0272\n",
      "Epoch 919/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 919: val_loss improved from 0.02719 to 0.02717, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0222 - val_loss: 0.0272\n",
      "Epoch 920/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0083\n",
      "Epoch 920: val_loss improved from 0.02717 to 0.02715, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0238 - val_loss: 0.0271\n",
      "Epoch 921/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0242\n",
      "Epoch 921: val_loss improved from 0.02715 to 0.02713, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0242 - val_loss: 0.0271\n",
      "Epoch 922/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0091\n",
      "Epoch 922: val_loss improved from 0.02713 to 0.02711, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0194 - val_loss: 0.0271\n",
      "Epoch 923/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0080\n",
      "Epoch 923: val_loss improved from 0.02711 to 0.02709, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0231 - val_loss: 0.0271\n",
      "Epoch 924/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0245\n",
      "Epoch 924: val_loss improved from 0.02709 to 0.02707, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0245 - val_loss: 0.0271\n",
      "Epoch 925/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0252\n",
      "Epoch 925: val_loss improved from 0.02707 to 0.02705, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 0.0252 - val_loss: 0.0271\n",
      "Epoch 926/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0090\n",
      "Epoch 926: val_loss improved from 0.02705 to 0.02703, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0221 - val_loss: 0.0270\n",
      "Epoch 927/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0209\n",
      "Epoch 927: val_loss improved from 0.02703 to 0.02701, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0209 - val_loss: 0.0270\n",
      "Epoch 928/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0083\n",
      "Epoch 928: val_loss improved from 0.02701 to 0.02700, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 0.0250 - val_loss: 0.0270\n",
      "Epoch 929/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 929: val_loss improved from 0.02700 to 0.02698, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 0.0213 - val_loss: 0.0270\n",
      "Epoch 930/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0099\n",
      "Epoch 930: val_loss improved from 0.02698 to 0.02696, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0324 - val_loss: 0.0270\n",
      "Epoch 931/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0100\n",
      "Epoch 931: val_loss improved from 0.02696 to 0.02694, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0256 - val_loss: 0.0269\n",
      "Epoch 932/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0096\n",
      "Epoch 932: val_loss improved from 0.02694 to 0.02693, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0264 - val_loss: 0.0269\n",
      "Epoch 933/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0270\n",
      "Epoch 933: val_loss improved from 0.02693 to 0.02691, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0270 - val_loss: 0.0269\n",
      "Epoch 934/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0075\n",
      "Epoch 934: val_loss improved from 0.02691 to 0.02689, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 0.0188 - val_loss: 0.0269\n",
      "Epoch 935/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0106\n",
      "Epoch 935: val_loss improved from 0.02689 to 0.02687, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0226 - val_loss: 0.0269\n",
      "Epoch 936/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0096\n",
      "Epoch 936: val_loss improved from 0.02687 to 0.02686, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0206 - val_loss: 0.0269\n",
      "Epoch 937/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0092\n",
      "Epoch 937: val_loss improved from 0.02686 to 0.02684, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0309 - val_loss: 0.0268\n",
      "Epoch 938/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0082\n",
      "Epoch 938: val_loss improved from 0.02684 to 0.02682, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0216 - val_loss: 0.0268\n",
      "Epoch 939/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0248\n",
      "Epoch 939: val_loss improved from 0.02682 to 0.02680, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0248 - val_loss: 0.0268\n",
      "Epoch 940/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0210\n",
      "Epoch 940: val_loss improved from 0.02680 to 0.02679, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0210 - val_loss: 0.0268\n",
      "Epoch 941/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0086\n",
      "Epoch 941: val_loss improved from 0.02679 to 0.02677, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0249 - val_loss: 0.0268\n",
      "Epoch 942/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0093\n",
      "Epoch 942: val_loss improved from 0.02677 to 0.02675, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0247 - val_loss: 0.0268\n",
      "Epoch 943/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 943: val_loss improved from 0.02675 to 0.02673, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0222 - val_loss: 0.0267\n",
      "Epoch 944/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0206\n",
      "Epoch 944: val_loss improved from 0.02673 to 0.02672, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 0.0206 - val_loss: 0.0267\n",
      "Epoch 945/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0079\n",
      "Epoch 945: val_loss improved from 0.02672 to 0.02670, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0193 - val_loss: 0.0267\n",
      "Epoch 946/1000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.0127\n",
      "Epoch 946: val_loss improved from 0.02670 to 0.02668, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 122ms/step - loss: 0.0225 - val_loss: 0.0267\n",
      "Epoch 947/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0074\n",
      "Epoch 947: val_loss improved from 0.02668 to 0.02667, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 101ms/step - loss: 0.0254 - val_loss: 0.0267\n",
      "Epoch 948/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0260\n",
      "Epoch 948: val_loss improved from 0.02667 to 0.02665, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 104ms/step - loss: 0.0260 - val_loss: 0.0267\n",
      "Epoch 949/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0219\n",
      "Epoch 949: val_loss improved from 0.02665 to 0.02663, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0219 - val_loss: 0.0266\n",
      "Epoch 950/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0088\n",
      "Epoch 950: val_loss improved from 0.02663 to 0.02662, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0351 - val_loss: 0.0266\n",
      "Epoch 951/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0083\n",
      "Epoch 951: val_loss improved from 0.02662 to 0.02660, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 0.0210 - val_loss: 0.0266\n",
      "Epoch 952/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0067\n",
      "Epoch 952: val_loss improved from 0.02660 to 0.02658, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 0.0201 - val_loss: 0.0266\n",
      "Epoch 953/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0146\n",
      "Epoch 953: val_loss improved from 0.02658 to 0.02656, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0146 - val_loss: 0.0266\n",
      "Epoch 954/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0225\n",
      "Epoch 954: val_loss improved from 0.02656 to 0.02654, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 103ms/step - loss: 0.0225 - val_loss: 0.0265\n",
      "Epoch 955/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0109\n",
      "Epoch 955: val_loss improved from 0.02654 to 0.02653, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0252 - val_loss: 0.0265\n",
      "Epoch 956/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0212\n",
      "Epoch 956: val_loss improved from 0.02653 to 0.02651, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.0212 - val_loss: 0.0265\n",
      "Epoch 957/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0092\n",
      "Epoch 957: val_loss improved from 0.02651 to 0.02649, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0315 - val_loss: 0.0265\n",
      "Epoch 958/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0085\n",
      "Epoch 958: val_loss improved from 0.02649 to 0.02647, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0266 - val_loss: 0.0265\n",
      "Epoch 959/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0084\n",
      "Epoch 959: val_loss improved from 0.02647 to 0.02646, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0238 - val_loss: 0.0265\n",
      "Epoch 960/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0089\n",
      "Epoch 960: val_loss improved from 0.02646 to 0.02644, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0237 - val_loss: 0.0264\n",
      "Epoch 961/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0078\n",
      "Epoch 961: val_loss improved from 0.02644 to 0.02643, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0250 - val_loss: 0.0264\n",
      "Epoch 962/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0115\n",
      "Epoch 962: val_loss improved from 0.02643 to 0.02641, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0189 - val_loss: 0.0264\n",
      "Epoch 963/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0086\n",
      "Epoch 963: val_loss improved from 0.02641 to 0.02639, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0190 - val_loss: 0.0264\n",
      "Epoch 964/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0257\n",
      "Epoch 964: val_loss improved from 0.02639 to 0.02638, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 0.0257 - val_loss: 0.0264\n",
      "Epoch 965/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0087\n",
      "Epoch 965: val_loss improved from 0.02638 to 0.02636, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 0.0273 - val_loss: 0.0264\n",
      "Epoch 966/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0085\n",
      "Epoch 966: val_loss improved from 0.02636 to 0.02634, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0247 - val_loss: 0.0263\n",
      "Epoch 967/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0069\n",
      "Epoch 967: val_loss improved from 0.02634 to 0.02633, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 0.0229 - val_loss: 0.0263\n",
      "Epoch 968/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0088\n",
      "Epoch 968: val_loss improved from 0.02633 to 0.02631, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0217 - val_loss: 0.0263\n",
      "Epoch 969/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0096\n",
      "Epoch 969: val_loss improved from 0.02631 to 0.02629, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0179 - val_loss: 0.0263\n",
      "Epoch 970/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0239\n",
      "Epoch 970: val_loss improved from 0.02629 to 0.02628, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 126ms/step - loss: 0.0239 - val_loss: 0.0263\n",
      "Epoch 971/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0101\n",
      "Epoch 971: val_loss improved from 0.02628 to 0.02626, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0272 - val_loss: 0.0263\n",
      "Epoch 972/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0069\n",
      "Epoch 972: val_loss improved from 0.02626 to 0.02624, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0303 - val_loss: 0.0262\n",
      "Epoch 973/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0094\n",
      "Epoch 973: val_loss improved from 0.02624 to 0.02623, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0226 - val_loss: 0.0262\n",
      "Epoch 974/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0090\n",
      "Epoch 974: val_loss improved from 0.02623 to 0.02621, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0219 - val_loss: 0.0262\n",
      "Epoch 975/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0237\n",
      "Epoch 975: val_loss improved from 0.02621 to 0.02619, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0237 - val_loss: 0.0262\n",
      "Epoch 976/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0204\n",
      "Epoch 976: val_loss improved from 0.02619 to 0.02617, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0204 - val_loss: 0.0262\n",
      "Epoch 977/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0058\n",
      "Epoch 977: val_loss improved from 0.02617 to 0.02615, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0273 - val_loss: 0.0262\n",
      "Epoch 978/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 978: val_loss improved from 0.02615 to 0.02613, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 0.0216 - val_loss: 0.0261\n",
      "Epoch 979/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0097\n",
      "Epoch 979: val_loss improved from 0.02613 to 0.02612, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0256 - val_loss: 0.0261\n",
      "Epoch 980/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0069\n",
      "Epoch 980: val_loss improved from 0.02612 to 0.02610, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0195 - val_loss: 0.0261\n",
      "Epoch 981/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0107\n",
      "Epoch 981: val_loss improved from 0.02610 to 0.02608, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 0.0211 - val_loss: 0.0261\n",
      "Epoch 982/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0083\n",
      "Epoch 982: val_loss improved from 0.02608 to 0.02606, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0160 - val_loss: 0.0261\n",
      "Epoch 983/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0103\n",
      "Epoch 983: val_loss improved from 0.02606 to 0.02605, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 0.0219 - val_loss: 0.0260\n",
      "Epoch 984/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0234\n",
      "Epoch 984: val_loss improved from 0.02605 to 0.02603, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 96ms/step - loss: 0.0234 - val_loss: 0.0260\n",
      "Epoch 985/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0078\n",
      "Epoch 985: val_loss improved from 0.02603 to 0.02601, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0253 - val_loss: 0.0260\n",
      "Epoch 986/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0065\n",
      "Epoch 986: val_loss improved from 0.02601 to 0.02599, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 105ms/step - loss: 0.0183 - val_loss: 0.0260\n",
      "Epoch 987/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0204\n",
      "Epoch 987: val_loss improved from 0.02599 to 0.02597, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 0.0204 - val_loss: 0.0260\n",
      "Epoch 988/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0108\n",
      "Epoch 988: val_loss improved from 0.02597 to 0.02596, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.0151 - val_loss: 0.0260\n",
      "Epoch 989/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0267\n",
      "Epoch 989: val_loss improved from 0.02596 to 0.02594, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0267 - val_loss: 0.0259\n",
      "Epoch 990/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0098\n",
      "Epoch 990: val_loss improved from 0.02594 to 0.02593, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 0.0188 - val_loss: 0.0259\n",
      "Epoch 991/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0082\n",
      "Epoch 991: val_loss improved from 0.02593 to 0.02591, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 0.0260 - val_loss: 0.0259\n",
      "Epoch 992/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0100\n",
      "Epoch 992: val_loss improved from 0.02591 to 0.02590, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0235 - val_loss: 0.0259\n",
      "Epoch 993/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0220\n",
      "Epoch 993: val_loss improved from 0.02590 to 0.02588, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0220 - val_loss: 0.0259\n",
      "Epoch 994/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0124\n",
      "Epoch 994: val_loss improved from 0.02588 to 0.02586, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0202 - val_loss: 0.0259\n",
      "Epoch 995/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0113\n",
      "Epoch 995: val_loss improved from 0.02586 to 0.02585, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0256 - val_loss: 0.0258\n",
      "Epoch 996/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0093\n",
      "Epoch 996: val_loss improved from 0.02585 to 0.02583, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0223 - val_loss: 0.0258\n",
      "Epoch 997/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0081\n",
      "Epoch 997: val_loss improved from 0.02583 to 0.02582, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0324 - val_loss: 0.0258\n",
      "Epoch 998/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0098\n",
      "Epoch 998: val_loss improved from 0.02582 to 0.02580, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0220 - val_loss: 0.0258\n",
      "Epoch 999/1000\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.0091\n",
      "Epoch 999: val_loss improved from 0.02580 to 0.02578, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 0.0244 - val_loss: 0.0258\n",
      "Epoch 1000/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0218\n",
      "Epoch 1000: val_loss improved from 0.02578 to 0.02577, saving model to OSTIM.h5\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.0218 - val_loss: 0.0258\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0258\n",
      "\n",
      "Test kayb: 2.6%\n",
      "3/3 [==============================] - 0s 6ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musab\\AppData\\Local\\Temp\\ipykernel_13504\\2208017571.py:123: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_prediction_df[\"Tahmin Edilen\"] = train_predict\n",
      "C:\\Users\\musab\\AppData\\Local\\Temp\\ipykernel_13504\\2208017571.py:125: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_prediction_df[\"Tahmin Edilen\"] = test_predict\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, SimpleRNN, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# Veriyi indirme ve inceleme\n",
    "ticker_symbol = 'OSTIM.IS'\n",
    "start_date = '2022-05-10'\n",
    "end_date = '2024-04-10'\n",
    "df = yf.download(ticker_symbol, period=\"10y\", interval=\"1mo\")\n",
    "df['Date'] = pd.to_datetime(df.index)\n",
    "\n",
    "# Veri hazrlama\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "OSTIM_df = df[[\"Date\", \"Close\"]]\n",
    "OSTIM_df.index = OSTIM_df[\"Date\"]\n",
    "OSTIM_df.drop(\"Date\", axis=1, inplace=True)\n",
    "result_df = OSTIM_df.copy()\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(OSTIM_df['Close'], color='blue')\n",
    "plt.ylabel('Fiyat')\n",
    "plt.title('OSTIM Grafii')\n",
    "plt.xlabel('Zaman')\n",
    "plt.show()\n",
    "\n",
    "# Veri nileme\n",
    "OSTIM_df = OSTIM_df.values.astype('float32')\n",
    "def split_data(dataframe, test_size):\n",
    "    pos = int(round(len(dataframe) * (1 - test_size)))\n",
    "    train = dataframe[:pos]\n",
    "    test = dataframe[pos:]\n",
    "    return train, test, pos\n",
    "\n",
    "train, test, pos = split_data(OSTIM_df, 0.20)\n",
    "scaler_train = MinMaxScaler(feature_range=(0, 1))\n",
    "train = scaler_train.fit_transform(train)\n",
    "scaler_test = MinMaxScaler(feature_range=(0, 1))\n",
    "test = scaler_test.fit_transform(test)\n",
    "\n",
    "def create_features(data, lookback):\n",
    "    X, Y = [], []\n",
    "    for i in range(lookback, len(data)):\n",
    "        X.append(data[i-lookback:i, 0])\n",
    "        Y.append(data[i, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "lookback = 1\n",
    "X_train, Y_train = create_features(train, lookback)\n",
    "X_test, Y_test = create_features(test, lookback)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "Y_train = Y_train.reshape(-1, 1)\n",
    "Y_test = Y_test.reshape(-1, 1)\n",
    "\n",
    "# Model oluturma\n",
    "model = Sequential([\n",
    "    SimpleRNN(units=20, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], lookback)),\n",
    "    Dropout(0.1),\n",
    "    SimpleRNN(units=10, activation='relu'),\n",
    "    Dropout(0.1),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Optimizasyon\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
    "\n",
    "# Callback'ler\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode=\"min\"),\n",
    "    ModelCheckpoint(filepath='OSTIM.h5', monitor='val_loss', mode='min',\n",
    "                    save_best_only=True, save_weights_only=False, verbose=1)\n",
    "]\n",
    "\n",
    "# Model eitimi\n",
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=Y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    callbacks=callbacks,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Eitim ve dorulama kaybn grselletirme\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Eitim Kayb')\n",
    "plt.plot(history.history['val_loss'], label='Dorulama Kayb')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Epok', fontsize=16)\n",
    "plt.ylabel('Kayp', fontsize=16)\n",
    "plt.ylim([0,max(plt.ylim())])\n",
    "plt.title('Eitim ve Dorulama Kayb', fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Model deerlendirme\n",
    "loss = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "print(\"\\nTest kayb: %.1f%%\" % (100.0 * loss))\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "train_predict = scaler_train.inverse_transform(train_predict)\n",
    "test_predict = scaler_test.inverse_transform(test_predict)\n",
    "Y_train = scaler_train.inverse_transform(Y_train)\n",
    "Y_test = scaler_test.inverse_transform(Y_test)\n",
    "\n",
    "\n",
    "# Tahminleri grselletirme\n",
    "train_prediction_df = result_df[lookback:pos]\n",
    "train_prediction_df[\"Tahmin Edilen\"] = train_predict\n",
    "test_prediction_df = result_df[pos+lookback:]\n",
    "test_prediction_df[\"Tahmin Edilen\"] = test_predict\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.plot(result_df, label='Gerek Deerler')\n",
    "plt.plot(train_prediction_df[\"Tahmin Edilen\"], color='blue', label='Eitim Tahmini')\n",
    "plt.plot(test_prediction_df[\"Tahmin Edilen\"], color=\"red\", label='Test Tahmini')\n",
    "plt.xlabel('Zaman')\n",
    "plt.ylabel('Fiyat')\n",
    "plt.title('OSTIMAN GRAF')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f5a5d23-2eb3-4c0f-bc79-ce308dce2080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eitim MAE: 0.20064128935337067\n",
      "Test MAE: 1.581221580505371\n",
      "Eitim MAPE: 19.833506643772125%\n",
      "Test MAPE: 34.45305824279785%\n",
      "Eitim RMSE: 0.2433050125837326\n",
      "Test RMSE: 1.9663987159729004\n"
     ]
    }
   ],
   "source": [
    "#MAE hesaplama\n",
    "train_mae = mean_absolute_error(Y_train, train_predict)\n",
    "test_mae = mean_absolute_error(Y_test, test_predict)\n",
    "print(f\"Eitim MAE: {train_mae}\")\n",
    "print(f\"Test MAE: {test_mae}\")\n",
    "\n",
    "#MAPE hesaplama\n",
    "train_mape = mean_absolute_percentage_error(Y_train, train_predict) * 100\n",
    "test_mape = mean_absolute_percentage_error(Y_test, test_predict) * 100\n",
    "print(f\"Eitim MAPE: {train_mape}%\")\n",
    "print(f\"Test MAPE: {test_mape}%\")\n",
    "\n",
    "#RMSE hesaplama\n",
    "train_rmse = np.sqrt(mean_squared_error(Y_train, train_predict))\n",
    "test_rmse = np.sqrt(mean_squared_error(Y_test, test_predict))\n",
    "print(f\"Eitim RMSE: {train_rmse}\")\n",
    "print(f\"Test RMSE: {test_rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorgpu",
   "language": "python",
   "name": "tensorgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
